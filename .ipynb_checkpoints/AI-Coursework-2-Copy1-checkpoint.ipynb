{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "In this project, I am going to build a neural network to classify bangla handwritten images into 10 different fashion categories. Each of the image is associated with only one category. For this purpose, I am using Fashion MNIST dataset from keras dataset. It contains 60,000 images for training and 10,000 images for testing. Each image is 28x28 grayscale, associated with a label from 10 fashion categories. The class labels are:\n",
    "\n",
    "Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel. This pixel-value is an integer between 0 and 255. In dataset each row is a separate image. It has 785 columns. The first column consists of the class labels and represents the article of clothing. The rest of the columns contain the pixel values of the associated image. So, 784 columns with pixel values of images. I will build a model that can place an image into one of the 10 class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "from skimage import data\n",
    "from skimage.transform import resize \n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "from keras import backend as k\n",
    "\n",
    "k.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Analysis\n",
    "Data preprocessing aims at making the raw data at hand more amenable to neural networks. Bangla handwritten dataset has been downloaded from this site []. It contains \n",
    "## 2.1 Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "path, dirs, files = next(os.walk(\"Dataset/train\"))\n",
    "path, dirs2, files2 = next(os.walk(\"Dataset/test\"))\n",
    "path, dirs3, files3 = next(os.walk(\"Dataset/validation\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Preprocessing Dataset\n",
    "As you already know by now, data should be formatted into appropriately pre-processed floating point tensors before being fed into our \n",
    "network. Currently, our data sits on a drive as JPEG files, so the steps for getting it into our network are roughly:\n",
    "\n",
    "* Read the picture files.\n",
    "* Decode the JPEG content to RBG grids of pixels.\n",
    "* Convert these into floating point tensors.\n",
    "* Rescale the pixel values (between 0 and 255) to the [0, 1] interval (as you know, neural networks prefer to deal with small input values).\n",
    "\n",
    "- **Change Label:** Each folder of dataset represnets different alphabets. There is 11 folders that starts from 1. Hence, I have changed their label starting from 0-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read image,change label\n",
    "def process_data(files,folder):\n",
    "    label_dict={'1':'0','2':'1','3':'2','4':'3','5':'4','6':'5','7':'6','8':'7','9':'8','10':'9','11':'10'}\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for file in files:\n",
    "        limg= data.imread(\"Dataset/\"+folder+'/'+file)\n",
    "        key = file.split('_')[-1].split('.')[0]\n",
    "        label_name = label_dict[key]\n",
    "        #img.resize(200,200)\n",
    "        y.append(label_name)\n",
    "        x.append(limg)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13200  13200\n",
      "4289  4289\n",
      "4294  4294\n"
     ]
    }
   ],
   "source": [
    "#read image,change label\n",
    "rx_train, y_train = process_data(files,'train')\n",
    "rx_test, y_test = process_data(files2,'test')\n",
    "rx_val, y_val = process_data(files3,'validation')\n",
    "print(len(rx_train),'',len(y_train))\n",
    "print(len(rx_test),'',len(y_test))\n",
    "print(len(rx_val),'',len(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of following five plots represents first five alphabets from train set. The first character is labeled as class 0, second character is labeled as class 10 and so on. So, other alphabets will have different labels, but similar alphabets will have same labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Show first 5 alphabets from train set \n",
    "for i in range(0, 5):\n",
    "    pyplot.subplot(330 + 1 + i)\n",
    "    pyplot.imshow(rx_train[i], cmap=pyplot.get_cmap('gray'))\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Reshape Data:** It is not possible to feed lists of integers into a neural network. Moreover, different layers are appropriate for different tensor formates and different types of data processing. I am going to use *densely connected* layers which is suitable for 2D tensors. In the dataset, actual images are 8 bit integers in 3D (6000,28,28) tensor formate. It needs to be reshaped and scaled within the interval of [0,1] so that the network can accept it as input. I convert these 2D matrix of 28x28 pixel images into 784 pixel of 1D float32 type matrix. To represent the label, I am using one-hot-encoding which turn the list of numeric or categorical values into the vectors of 0s and 1s.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.array(rx_train).reshape(len(rx_train),34,34,1)\n",
    "x_test=np.array(rx_test).reshape(len(rx_test),34,34,1)\n",
    "x_val=np.array(rx_val).reshape(len(rx_val),34,34,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Normalize Data:**  It is not possible to feed lists of integers into a neural network. Moreover, different layers are appropriate for different tensor formates and different types of data processing. I am going to use *densely connected* layers which is suitable for 2D tensors. In the dataset, actual images are 8 bit integers in 3D (6000,28,28) tensor formate. It needs to be reshaped and scaled within the interval of [0,1] so that the network can accept it as input. I convert these 2D matrix of 28x28 pixel images into 784 pixel of 1D float32 type matrix. To represent the label, I am using one-hot-encoding which turn the list of numeric or categorical values into the vectors of 0s and 1s. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train).astype('float32') / 255\n",
    "x_test = np.array(x_test).astype('float32') / 255\n",
    "x_val = np.array(x_val).astype('float32') / 255\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_val = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13200, 34, 34, 1)\n",
      "(4289, 34, 34, 1)\n",
      "(4294, 34, 34, 1)\n",
      "(13200, 11)\n",
      "(4289, 11)\n",
      "(4294, 11)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(x_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create Model\n",
    "\n",
    "The workflow will be as follows: First, training data (train_images and train_labels) will be passed into the neural network. The network will then learn to associate images and labels. Finally, the network will be tested by predicting for test_images, and verified whether these predictions match the labels from test_labels. For this assignment, I have applied following methods to classify my dataset. \n",
    "- Convolution Neural Network\n",
    "- Data Augmentation\n",
    "- Convolution Neural Network with Dropout and Batch Normalization\n",
    "- Depthwise Separable Convolution \n",
    "- Dense Neural Networks\n",
    "- Hyperparameter Optimization (DNN)\n",
    "- Hyperparameter Optimization (CNN)\n",
    "<p>In later sections, each method is explained along with trainning and testing process. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Convolution Neural Network (CNN)\n",
    "<p>The CNNs have several different filters consisting of trainable parameters which can convolve on a given image spatially to detect features like edges and shapes. These high number of filters essentially learn to capture spatial features from the image based on the learned weights through back propagation and stacked layers of filters can be used to detect complex spatial shapes from the spatial features at every subsequent level. Convolutions are defined by two key parameters:</p>\n",
    " - Size of the patches extracted from the inputs: In this case, it is 3 × 3.\n",
    "\n",
    " - Depth of the output feature map: The number of filters computed by the convolution. This model started with a depth of 16 and ended with a depth of 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "def create_model(option):    \n",
    "    if(option==1):   #Simple CNN\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Conv2D(16, (3, 3), activation='relu', input_shape=(34, 34, 1)))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "        model.summary()\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(32, activation='relu'))\n",
    "        model.add(layers.Dense(11, activation='softmax'))\n",
    "        return model\n",
    "    elif(option==2):  #CNN with dropout\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Conv2D(16, (3, 3), activation='relu',input_shape=(34, 34, 1)))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Dropout(0.25))\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu',padding='same'))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Dropout(0.25))\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu',padding='same'))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Dropout(0.25))\n",
    "       \n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dropout(0.25))\n",
    "        model.add(layers.Dense(64, activation='relu'))\n",
    "        model.add(layers.Dense(11, activation='softmax'))\n",
    "        return model\n",
    "    elif(option ==3):   #CNN with Batch Normalization\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Conv2D(16, (3, 3), activation='relu',input_shape=(34, 34, 1)))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        #model.add(layers.Dropout(0.25))\n",
    "\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu',padding='same'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        #model.add(layers.Dropout(0.25))\n",
    "\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu',padding='same'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        #model.add(layers.Dropout(0.25))\n",
    "\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu',padding='same'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        #model.add(layers.Dropout(0.25))\n",
    "\n",
    "        model.add(layers.Flatten())\n",
    "        #model.add(layers.Dropout(0.25))\n",
    "        model.add(layers.Dense(64, activation='relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dense(11, activation='softmax'))\n",
    "        return model\n",
    "    else:                #CNN with Batch Normalization and Dropout\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Conv2D(16, (3, 3), activation='relu',input_shape=(34, 34, 1)))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Dropout(0.25))\n",
    "\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu',padding='same'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Dropout(0.25))\n",
    "\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu',padding='same'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Dropout(0.25))\n",
    "\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu',padding='same'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Dropout(0.25))\n",
    "\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dropout(0.25))\n",
    "        model.add(layers.Dense(64, activation='relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dense(11, activation='softmax'))      \n",
    "        return model  \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu', input_shape=(34, 34, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 5, 5, 32)          9248      \n",
      "=================================================================\n",
      "Total params: 14,048\n",
      "Trainable params: 14,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(11, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_train,y_train,x_val,y_val,model):\n",
    "    model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    history = model.fit(x_train, \n",
    "          y_train, \n",
    "          epochs=20,\n",
    "          batch_size = 10,\n",
    "          validation_data=(x_val,y_val))\n",
    "    history_dict = history.history\n",
    "    return history_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13200 samples, validate on 4294 samples\n",
      "Epoch 1/20\n",
      "13200/13200 [==============================] - 10s 778us/step - loss: 0.0237 - acc: 0.9942 - val_loss: 0.9506 - val_acc: 0.8749\n",
      "Epoch 2/20\n",
      "13200/13200 [==============================] - 10s 736us/step - loss: 0.0241 - acc: 0.9943 - val_loss: 0.9277 - val_acc: 0.8836\n",
      "Epoch 3/20\n",
      "13200/13200 [==============================] - 11s 797us/step - loss: 0.0238 - acc: 0.9939 - val_loss: 1.0094 - val_acc: 0.8733\n",
      "Epoch 4/20\n",
      "13200/13200 [==============================] - 10s 739us/step - loss: 0.0247 - acc: 0.9948 - val_loss: 1.0661 - val_acc: 0.8759\n",
      "Epoch 5/20\n",
      "13200/13200 [==============================] - 10s 781us/step - loss: 0.0220 - acc: 0.9953 - val_loss: 1.1312 - val_acc: 0.8733\n",
      "Epoch 6/20\n",
      "13200/13200 [==============================] - 9s 677us/step - loss: 0.0230 - acc: 0.9947 - val_loss: 1.0985 - val_acc: 0.8728\n",
      "Epoch 7/20\n",
      "13200/13200 [==============================] - 9s 693us/step - loss: 0.0226 - acc: 0.9943 - val_loss: 1.0048 - val_acc: 0.8845\n",
      "Epoch 8/20\n",
      "13200/13200 [==============================] - 10s 724us/step - loss: 0.0202 - acc: 0.9958 - val_loss: 1.0709 - val_acc: 0.8752\n",
      "Epoch 9/20\n",
      "13200/13200 [==============================] - 10s 729us/step - loss: 0.0242 - acc: 0.9955 - val_loss: 1.1520 - val_acc: 0.8707\n",
      "Epoch 10/20\n",
      "13200/13200 [==============================] - 9s 704us/step - loss: 0.0188 - acc: 0.9958 - val_loss: 1.0499 - val_acc: 0.8677\n",
      "Epoch 11/20\n",
      "13200/13200 [==============================] - 9s 676us/step - loss: 0.0209 - acc: 0.9955 - val_loss: 1.2080 - val_acc: 0.8752\n",
      "Epoch 12/20\n",
      "13200/13200 [==============================] - 10s 727us/step - loss: 0.0187 - acc: 0.9958 - val_loss: 1.1810 - val_acc: 0.8759\n",
      "Epoch 13/20\n",
      "13200/13200 [==============================] - 9s 702us/step - loss: 0.0217 - acc: 0.9958 - val_loss: 1.1336 - val_acc: 0.8768\n",
      "Epoch 14/20\n",
      "13200/13200 [==============================] - 10s 788us/step - loss: 0.0205 - acc: 0.9960 - val_loss: 1.2346 - val_acc: 0.8701\n",
      "Epoch 15/20\n",
      "13200/13200 [==============================] - 10s 754us/step - loss: 0.0188 - acc: 0.9957 - val_loss: 1.2351 - val_acc: 0.8754\n",
      "Epoch 16/20\n",
      "13200/13200 [==============================] - 9s 668us/step - loss: 0.0216 - acc: 0.9961 - val_loss: 1.1774 - val_acc: 0.8752\n",
      "Epoch 17/20\n",
      "13200/13200 [==============================] - 10s 726us/step - loss: 0.0230 - acc: 0.9963 - val_loss: 1.3627 - val_acc: 0.8728\n",
      "Epoch 18/20\n",
      "13200/13200 [==============================] - 9s 696us/step - loss: 0.0202 - acc: 0.9972 - val_loss: 1.2990 - val_acc: 0.8696\n",
      "Epoch 19/20\n",
      "13200/13200 [==============================] - 9s 676us/step - loss: 0.0178 - acc: 0.9972 - val_loss: 1.2937 - val_acc: 0.8766\n",
      "Epoch 20/20\n",
      "13200/13200 [==============================] - 11s 808us/step - loss: 0.0177 - acc: 0.9972 - val_loss: 1.3428 - val_acc: 0.8733\n"
     ]
    }
   ],
   "source": [
    "history = train_model(x_train,y_train,x_val,y_val,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(x_train, \n",
    "          y_train, \n",
    "          epochs=20,\n",
    "          batch_size = 10,\n",
    "          validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(history):\n",
    "    import matplotlib.pyplot as plt\n",
    "    acc = history['acc']\n",
    "    val_acc = history['val_acc']\n",
    "    loss = history['loss']\n",
    "    val_loss =history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    print('Position of minimum val_loss: ',np.argmin(val_loss)+1, 'Position of maximum val_acc: ',np.argmax(val_acc)+1)\n",
    "\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position of minimum val_loss:  2 Position of maximum val_acc:  7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_graph(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "overfitting begins after 7 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model,x_test,y_test,step):\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test,steps=step)\n",
    "    test_acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.argmin(val_loss)+1, np.argmax(val_acc)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model,x_test,y_test,(np.argmin(history.history['val_loss'])+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.argmin(val_loss)+1, np.argmax(val_acc)+1\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test,steps=7)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## predicted Image\n",
    "predicted_classes = fashion_model.predict(test_X)\n",
    "predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
    "predicted_classes.shape, test_Y.shape\n",
    "\n",
    "\n",
    "correct = np.where(predicted_classes==test_Y)[0]\n",
    "print \"Found %d correct labels\" % len(correct)\n",
    "for i, correct in enumerate(correct[:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(test_X[correct].reshape(28,28), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[correct], test_Y[correct]))\n",
    "    plt.tight_layout()\n",
    "######\n",
    "\n",
    "incorrect = np.where(predicted_classes!=test_Y)[0]\n",
    "print \"Found %d incorrect labels\" % len(incorrect)\n",
    "for i, incorrect in enumerate(incorrect[:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(test_X[incorrect].reshape(28,28), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[incorrect], test_Y[incorrect]))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Convolution Neural Network with Dropout and Batch Normalization\n",
    "- new Convent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#train with data augmentation generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    \"Dataset/train\",\n",
    "    target_size=(34, 34),\n",
    "    batch_size=32,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical')\n",
    "\n",
    "#test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    \"Dataset/validation\",\n",
    "    target_size=(34, 34),\n",
    "    batch_size=32,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu',input_shape=(34, 34, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',padding='same'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',padding='same'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',padding='same'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(11, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              #optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, \n",
    "          y_train, \n",
    "          epochs=20,\n",
    "          batch_size = 10,\n",
    "          validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = model.fit_generator(\n",
    " #   datagen.flow(x_train,y_train,batch_size=32),\n",
    " #   steps_per_epoch=10,\n",
    " #   epochs=15,\n",
    " #   validation_data=(x_val,y_val),\n",
    "  #  validation_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.argmin(val_loss)+1, np.argmax(val_acc)+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test,y_test,steps=11)\n",
    "print('test acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu',input_shape=(34, 34, 1)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "#model.add(layers.Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "#model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "#model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "#model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "#model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(11, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              #optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, \n",
    "          y_train, \n",
    "          epochs=20,\n",
    "          batch_size = 10,\n",
    "          validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_graph(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print(np.argmin(val_loss)+1, np.argmax(val_acc)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.argmin(val_loss)+1, np.argmax(val_acc)+1)\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test,steps=7)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Depthwise Separable Convolution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.SeparableConv2D(32, 3,activation='relu',input_shape=(34, 34, 1,)))\n",
    "model.add(layers.SeparableConv2D(64, 3, activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(layers.SeparableConv2D(64, 3, activation='relu'))\n",
    "model.add(layers.SeparableConv2D(128, 3, activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(layers.SeparableConv2D(64, 3, activation='relu'))\n",
    "model.add(layers.SeparableConv2D(128, 3, activation='relu'))\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(11, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, \n",
    "          y_train, \n",
    "          epochs=20,\n",
    "          batch_size = 10,\n",
    "          validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(history)\n",
    "#print(np.argmin(val_loss)+1, np.argmax(val_acc)+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test,steps=20)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Inspecting Models Using Keras Callback\n",
    "A good use of checkpointing is to output the model weights each time an improvement is observed during training. Checkpointing is setup to save the network weights only when there is an improvement in classification accuracy on the validation dataset (monitor=’val_acc’ and mode=’max’). The weights are stored in a file that includes the score in the filename (weights-improvement-{val_acc=.2f}.hdf5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.utils\n",
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "    monitor='val_acc',\n",
    "    patience=1,\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "    filepath='my_model.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=10,)\n",
    "]\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "            metrics=['acc'])\n",
    "model.fit(x_train, y_train, epochs=20,batch_size=32,callbacks=callbacks_list,validation_data=(x_val, y_val))\n",
    "\n",
    "# Save the model\n",
    "#model.save('cats_and_dogs_small_2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Dense Neural Networks\n",
    "## 3.7 Hyperparameter Optimization (DNN)\n",
    "## 3.8 Hyperparameter Optimization (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9 Model Ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9 Callback/ early stopping\n",
    "\n",
    "https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Result Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
