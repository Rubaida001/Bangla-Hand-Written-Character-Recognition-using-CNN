{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "In this project, I will build a classifier to identify Bangla handwritten images. Bangla is the fourth highest spoken language in the world based on the population. There are 10 digits and 50 characters in vowel and consonant in Bangla language where some contains additional sign up and/or below. For this assignment, I have considered 11 vowels of the language to classify. I will build a model that can place an image into one of the 11 class labels. \n",
    "\n",
    "To do so, I have implemented Convolutional Neural Networks (CNN) on this dataset. I have included differnt parameters like, dropout, image augmentation, batch normalization to improve the model. To monitor the model's performance I have used keras callback, early stopping and reducing/increasing learning rate techniques. Finally, I have adopted hyper parameter optimization technique to find out the best model for classification. Moreover, a Dense Neural Network (DNN) with hyper parameter optimization technique has been implemented to make a comparison with CNN. The next sections include all these processes as follows: preparing data, building models, inspecting built models, optimization technique, result analysis and final remarks.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "from skimage import data\n",
    "from skimage.transform import resize \n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import backend as k\n",
    "\n",
    "k.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Analysis\n",
    "Bangla handwritten dataset has been downloaded from this site [1]. It contains samples of 50 Bangla basic characters, 10 Bangla numerals and 24 selected compound characters. 2000 handwriting samples for each of the 84 characters were collected, digitized and pre-processed. As I am using 11 Bangla vowel character, it includes total 21783 images. I have split this data into 60:20:20 portion for training, validation and testing purpose. That's why, 13200 images are for training, 4289 for testing and rest of the images are for testing. \n",
    "## 2.1 Load Dataset\n",
    "With all these data, I have created three folders: train, test, validation to keep respective dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "path, dirs, files = next(os.walk(\"Dataset/train\"))\n",
    "path, dirs2, files2 = next(os.walk(\"Dataset/test\"))\n",
    "path, dirs3, files3 = next(os.walk(\"Dataset/validation\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Preprocessing Dataset\n",
    "Data preprocessing aims at making the raw data at hand more amenable to neural networks. Data should be formatted into appropriately pre-processed floating point tensors before being fed into the network. So, I have applied following procedures to prepare dataset.\n",
    "- **Change Label:** In this dataset, each folder represnets different alphabets. There is 11 folders that starts from 1. Hence, I have changed their label that starting from 0-10. Each of the number represents different character. The class labels are as follow:\n",
    "\n",
    "                 <img src=\"img/alim.jpg\" alt=\"Drawing\" style=\"width: 800px;\"/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read image,change label\n",
    "def process_data(files,folder):\n",
    "    label_dict={'1':'0','2':'1','3':'2','4':'3','5':'4','6':'5','7':'6','8':'7','9':'8','10':'9','11':'10'}\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for file in files:\n",
    "        limg= data.imread(\"Dataset/\"+folder+'/'+file)\n",
    "        key = file.split('_')[-1].split('.')[0]\n",
    "        label_name = label_dict[key]\n",
    "        #img.resize(200,200)\n",
    "        y.append(label_name)\n",
    "        x.append(limg)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read image,change label\n",
    "rx_train, y_train = process_data(files,'train')\n",
    "rx_test, y_test = process_data(files2,'test')\n",
    "rx_val, y_val = process_data(files3,'validation')\n",
    "print(len(rx_train),'',len(y_train))\n",
    "print(len(rx_test),'',len(y_test))\n",
    "print(len(rx_val),'',len(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of following five plots represents first five alphabets from train set. The first character is labeled as class 0, second character is labeled as class 10 and so on. So, other alphabets will have different labels, but similar alphabets will have same labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show first 5 alphabets from train set \n",
    "for i in range(0, 5):\n",
    "    pyplot.subplot(330 + 1 + i)\n",
    "    pyplot.imshow(rx_train[i], cmap=pyplot.get_cmap('gray'))\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Reshape Data:** Each image is in grayscale format with different sizes in corresponding dataset. Whereas, Conv2D and MaxPooling2D layer is a 3D tensor of shape (height, width, channels) in convolutional model. So, I have converted each image into (34, 34, 1) shape. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.array(rx_train).reshape(len(rx_train),34,34,1)\n",
    "x_test=np.array(rx_test).reshape(len(rx_test),34,34,1)\n",
    "x_val=np.array(rx_val).reshape(len(rx_val),34,34,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Normalize Data:** As actual images are 8 bit integers, I converted theme into floating point tensors.Then, rescale the pixel values (between 0 and 255) to the [0, 1] interval as neural networks prefer to deal with small input values. To represent the label, I am using one-hot-encoding which turn the list of numeric or categorical values into the vectors of 0s and 1s.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train).astype('float32') / 255\n",
    "x_test = np.array(x_test).astype('float32') / 255\n",
    "x_val = np.array(x_val).astype('float32') / 255\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_val = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(x_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create Model\n",
    "\n",
    "The workflow will be as follows: First, training data (train_images and train_labels) will be passed into the neural network. The network will then learn to associate images and labels. Finally, the network will be tested by predicting for test_images, and verified whether these predictions match the labels from test_labels. For this assignment, I have applied following methods to classify my dataset. \n",
    "- Convolution Neural Network\n",
    "- Data Augmentation\n",
    "- Convolution Neural Network with Dropout and Batch Normalization\n",
    "- Depthwise Separable Convolution \n",
    "- Dense Neural Networks\n",
    "- Hyperparameter Optimization (DNN)\n",
    "- Hyperparameter Optimization (CNN)\n",
    "<p>In later sections, each method is explained along with trainning and testing process. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Convolution Neural Network (CNN)\n",
    "<p>The CNNs have several different filters consisting of trainable parameters which can convolve on a given image spatially to detect features like edges and shapes. These high number of filters essentially learn to capture spatial features from the image based on the learned weights through back propagation and stacked layers of filters can be used to detect complex spatial shapes from the spatial features at every subsequent level. Convolutions are defined by two key parameters:</p>\n",
    " - Size of the patches extracted from the inputs: In this case, it is 3 × 3.\n",
    "\n",
    " - Depth of the output feature map: The number of filters computed by the convolution. This model started with a depth of 16 and ended with a depth of 128.\n",
    "\n",
    "Other parameters for this model are:\n",
    "\n",
    "* Activation function for each layer is 'relu' and for final layer is 'softmax'\n",
    "* As it is a multi-label classification problem, I have selected catrgorical_crossentropy for loss function.\n",
    "* Optimizer = rmsprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "def create_model(option):    \n",
    "    if(option==1):   #Simple CNN\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Conv2D(16, (3, 3), activation='relu', input_shape=(34, 34, 1)))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.summary()\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(128, activation='relu'))\n",
    "        model.add(layers.Dense(11, activation='softmax'))\n",
    "        return model\n",
    "    elif(option==2):  #CNN with dropout\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Conv2D(16, (3, 3), activation='relu',input_shape=(34, 34, 1)))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Dropout(0.25))\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu',padding='same'))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Dropout(0.25))\n",
    "        model.add(layers.Conv2D(64, (3, 3), activation='relu',padding='same'))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Dropout(0.25))\n",
    "        model.summary()\n",
    "\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dropout(0.25))\n",
    "        model.add(layers.Dense(128, activation='relu'))\n",
    "        model.add(layers.Dense(11, activation='softmax'))\n",
    "        return model\n",
    "    elif(option ==3):   #CNN with Batch Normalization\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Conv2D(16, (3, 3), activation='relu',input_shape=(34, 34, 1)))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.MaxPooling2D((2, 2)))       \n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu',padding='same'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.MaxPooling2D((2, 2)))       \n",
    "        model.add(layers.Conv2D(64, (3, 3), activation='relu',padding='same'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.summary()\n",
    "    \n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(128, activation='relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dense(11, activation='softmax'))\n",
    "        return model\n",
    "    else:                #CNN with Batch Normalization and Dropout\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Conv2D(16, (3, 3), activation='relu',input_shape=(34, 34, 1)))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Dropout(0.25))\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu',padding='same'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Dropout(0.25))\n",
    "        model.add(layers.Conv2D(64, (3, 3), activation='relu',padding='same'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Dropout(0.25))\n",
    "        model.summary()\n",
    "\n",
    "\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dropout(0.25))\n",
    "        model.add(layers.Dense(128, activation='relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dense(11, activation='softmax'))      \n",
    "        return model     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Simple CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_train,y_train,x_val,y_val,model):\n",
    "    model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    history = model.fit(x_train, \n",
    "          y_train, \n",
    "          epochs=20,\n",
    "          batch_size = 10,\n",
    "          validation_data=(x_val,y_val))\n",
    "    history_dict = history.history\n",
    "    return history_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create graph for training and validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(history):\n",
    "    acc = history['acc']\n",
    "    val_acc = history['val_acc']\n",
    "    loss = history['loss']\n",
    "    val_loss =history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    print('Position of minimum val_loss: ',np.argmin(val_loss)+1, 'Position of maximum val_acc: ',np.argmax(val_acc)+1)\n",
    "\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model,x_test,y_test,step):\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test,steps=step)\n",
    "    print('Test Accuracy: ',test_acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = train_model(x_train,y_train,x_val,y_val,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_graph(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Model\n",
    "test_model(model,x_test,y_test,(np.argmin(history['val_loss'])+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## predicted Image\n",
    "predicted_classes = model.predict(x_test)\n",
    "predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
    "predicted_classes.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "correct = np.where(predicted_classes==y_test)[0]\n",
    "print (\"Found correct labels\", len(correct))\n",
    "for i, correct in enumerate(correct[:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(x_test[correct].reshape(34,34), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[correct], y_test[correct]))\n",
    "    plt.tight_layout()\n",
    "######\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect = np.where(predicted_classes!=y_test)[0]\n",
    "print (\"Found incorrect labels\",len(incorrect))\n",
    "for i, incorrect in enumerate(incorrect[:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(x_test[incorrect].reshape(34,34), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[incorrect], y_test[incorrect]))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Data Augmentation\n",
    "In the above model, minimum validation loss is found at position 3. It is quite an indication of overfitting. Overfitting is caused by having too few samples to learn from, unable to train a model that can generalize to new data. Data augmentation is a popular technique to prevent overfiting. It takes the approach of generating more training data from existing training samples, by augmenting the samples via a number of random transformations that yield believable-looking images. The goal is that at training time, model will never see the exact same picture twice. In following section I have generated train data using ImageDataGenerator function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=25,\n",
    "    width_shift_range=0.005,\n",
    "    height_shift_range=0.005,\n",
    "    shear_range=0.02,\n",
    "    zoom_range=0.02,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = create_model(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_augmentation(x_train,y_train,x_val,y_val,model):\n",
    "    model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    history = model.fit_generator(\n",
    "        datagen.flow(x_train,y_train,batch_size=10),\n",
    "        steps_per_epoch=10,\n",
    "        epochs=20,\n",
    "        validation_data=(x_val,y_val),\n",
    "        validation_steps=10)\n",
    "    history_dict = history.history\n",
    "    return history_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = train_with_augmentation(x_train,y_train,x_val,y_val,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Validation Graph\n",
    "create_graph(history)\n",
    "\n",
    "# Evaluate the model\n",
    "test_model(model,x_test,y_test,(np.argmin(history['val_loss'])+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Convolution Neural Network with Dropout and Batch Normalization\n",
    "### 3.3.1 CNN with Dropout\n",
    "Another technique to reduce overfitting is to add dropout layer in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = create_model(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "#history = train_model(x_train,y_train,x_val,y_val,model)\n",
    "history = train_with_augmentation(x_train,y_train,x_val,y_val,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Validation Graph\n",
    "create_graph(history)\n",
    "\n",
    "# Evaluate the model\n",
    "test_model(model,x_test,y_test,(np.argmin(history['val_loss'])+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 CNN with Batch Normalization\n",
    "Batch normalization is a type of layer (BatchNormalization in Keras) that can adaptively normalize data even as the mean and\n",
    "variance change over time during training. It works by internally maintaining an exponential moving average of the batch-wise mean and variance of the data seen during training. The main effect of batch normalization is that it helps with gradient propagation and thus allows for deeper networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = create_model(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "#history = train_model(x_train,y_train,x_val,y_val,model)\n",
    "history = train_with_augmentation(x_train,y_train,x_val,y_val,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Validation Graph\n",
    "create_graph(history)\n",
    "\n",
    "# Evaluate the model\n",
    "test_model(model,x_test,y_test,(np.argmin(history['val_loss'])+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3 Convolution Neural Network with Dropout and Batch Normalization\n",
    "I have combined both dropout and normalization to improve the classification rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = create_model(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* After creating the model, I have implemented it on both normal dataset and augmentic dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "history = train_model(x_train,y_train,x_val,y_val,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with augmentated data\n",
    "history = train_with_augmentation(x_train,y_train,x_val,y_val,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Validation Graph\n",
    "create_graph(history)\n",
    "\n",
    "# Evaluate the model\n",
    "test_model(model,x_test,y_test,(np.argmin(history['val_loss'])+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Depthwise Separable Convolution \n",
    "Depthwise Separable convolutions consists in performing just the first step in a depthwise spatial convolution (which acts on each input channel separately). It requires significantly fewer parameters and involves fewer computations, thus resulting in smaller, speedier models. And because it’s a more representationally efficient way to perform convolution, it tends to learn\n",
    "better representations using less data, resulting in better-performing models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.SeparableConv2D(32, 3,activation='relu',input_shape=(34, 34, 1,)))\n",
    "model.add(layers.SeparableConv2D(64, 3, activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(layers.SeparableConv2D(64, 3, activation='relu'))\n",
    "model.add(layers.SeparableConv2D(128, 3, activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(layers.SeparableConv2D(64, 3, activation='relu'))\n",
    "model.add(layers.SeparableConv2D(128, 3, activation='relu'))\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(11, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['acc'])\n",
    "history = model.fit(x_train, \n",
    "          y_train, \n",
    "          epochs=20,\n",
    "          batch_size = 10,\n",
    "          validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "create_graph(history_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test,steps=9)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Inspecting Models Using Keras Callback\n",
    "* Early Stopping: EarlyStopping callback can use to interrupt training once a target metric being monitored has stopped improving for a fixed number of epochs. This callback is typically used in combination with ModelCheckpoint, which lets continually save the model during training.\n",
    "* Checkpointing: A good use of checkpointing is to output the model weights each time an improvement is observed during training. Checkpointing is setup to save the network weights only when there is an improvement in classification accuracy on the validation dataset (monitor=’val_acc’ and mode=’max’). The weights are stored in a file that includes the score in the filename (weights-improvement-{val_acc=.2f}.hdf5).\n",
    "\n",
    "* ReduceLROnPlateau: You can use this callback to reduce the learning rate when the validation loss has stopped improving. Reducing or increasing the learning rate in case of a loss plateau is an effective strategy to get out of local minima during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.utils\n",
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "    monitor='val_acc',\n",
    "    patience=1,\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "    filepath='my_model.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=10,)\n",
    "]\n",
    "#Build Simple CNN\n",
    "model= create_model(1)\n",
    "\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "            metrics=['acc'])\n",
    "model.fit(x_train, y_train, epochs=50,batch_size=32,callbacks=callbacks_list,validation_data=(x_val, y_val),save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "After applying all these above methods, it is quite clear that using data augmentation does not improve the accuracy rate. Rather, models without augmentation look good. Using two differnet techniques (dropout and batch normalization), creates the best result. \n",
    "\n",
    "| Method \t| Dropout \t| Batch N \t| Epoch \t| Low Val_loss \t| Test Accuracy \t| Validation Accuracy \t|\n",
    "|:------:\t|:-------:\t|:-------:\t|:-----:\t|:------------:\t|:-------------:\t|:-------------------:\t|\n",
    "|   CNN  \t|    n    \t|    n    \t|   20  \t|       3      \t|    0.90837    \t|        0.8922       \t|\n",
    "|   CNN  \t|    y    \t|    n    \t|   20  \t|      13      \t|    0.925857   \t|        0.9059       \t|\n",
    "|   CNN  \t|    n    \t|    y    \t|   20  \t|       3      \t|    0.933784   \t|        0.9089       \t|\n",
    "|   CNN  \t|    y    \t|    y    \t|   20  \t|       3      \t|    0.93495    \t|        0.9459       \t|\n",
    "|   DSC  \t|    -    \t|    -    \t|   20  \t|       9      \t|    0.869667   \t|        0.8386       \t|\n",
    "                                     \n",
    "                            \n",
    "                            *** DSC - Depthwise Seperable Convolution\n",
    "                            **Result of Different Models without Data Augmentation**\n",
    "                            \n",
    "It was anticipiated that, depthwise seperable convolution model would minimize the complexity of basic convolution as well as improve the result. But it yields the worst performance for both augmented data and train/test set.                           \n",
    "                            \n",
    "\n",
    "                \n",
    "| Method \t| Dropout \t| Batch N \t| Epoch \t| Low Val_loss \t| Test Accuracy \t| Validation Accuracy \t|\n",
    "|:------:\t|:-------:\t|:-------:\t|:-----:\t|:------------:\t|:-------------:\t|:-------------------:\t|\n",
    "|   CNN  \t|    n    \t|    n    \t|   20  \t|      18      \t|    0.378876   \t|        0.381        \t|\n",
    "|   CNN  \t|    y    \t|    n    \t|   20  \t|      19      \t|    0.314059   \t|        0.326        \t|\n",
    "|   CNN  \t|    n    \t|    y    \t|   20  \t|       5      \t|    0.224528   \t|        0.3172       \t|\n",
    "|   CNN  \t|    y    \t|    y    \t|   20  \t|      19      \t|    0.276055   \t|        0.323        \t|\n",
    "|   DSC  \t|    -    \t|    -    \t|   20  \t|      14      \t|    0.089765   \t|        0.0915       \t|\n",
    "\n",
    "                             **Result of Different Models with Data Augmentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Dense Neural Networks\n",
    "I have applied DNN network on this dataset to check whether it improves the result. For this implementation, I have created 3 layers model with 16 hidden units except the output layer. Other then that, optimizer, activation function and loss function all are same in both CNN and DNN model. The **classification rate with this model is about 73%. ** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run DNN.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Hyperparameter Optimization (DNN)\n",
    "Hyperparameter optimization is a powerful technique that is an absolute requirement to get to state-of-the-art models on any task. There are lots of parameter and model architectures to build a single network. It is very time consuming to find a best set of layers, activation function and learning rate manually. In this assignment, I have used Hyperas library to select optimized parameters automatically for best model of DNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run DNNoptimizer.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 Hyperparameter Optimization (CNN)\n",
    "Another optimization technique is implemented on CNN model. Although using library makes it easy to find the optimized solution, still it is computationally expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import os, shutil\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from skimage.transform import resize\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from matplotlib import pyplot\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import to_categorical\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import keras\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import layers\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import models\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend as k\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from skimage import data\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'model_choice': hp.choice('model_choice', ['one', 'two']),\n",
      "        'Dropout': hp.uniform('Dropout', 0, 1),\n",
      "        'Dropout_1': hp.uniform('Dropout_1', 0, 1),\n",
      "        'Dropout_2': hp.uniform('Dropout_2', 0, 1),\n",
      "        'Dropout_3': hp.uniform('Dropout_3', 0, 1),\n",
      "        'Dense': hp.choice('Dense', [64, 128, 256]),\n",
      "        'Dropout_4': hp.uniform('Dropout_4', 0, 1),\n",
      "        'model_choice_1': hp.choice('model_choice_1', ['one', 'two']),\n",
      "        'Dense_1': hp.choice('Dense_1', [64, 128, 256]),\n",
      "        'Dropout_5': hp.uniform('Dropout_5', 0, 1),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "   1: \n",
      "   2: def process_data(files,folder):\n",
      "   3:     from skimage import data\n",
      "   4:     label_dict={'1':'0','2':'1','3':'2','4':'3','5':'4','6':'5','7':'6','8':'7','9':'8','10':'9','11':'10'}\n",
      "   5:     x=[]\n",
      "   6:     y=[]\n",
      "   7:     for file in files:\n",
      "   8:         limg= data.imread(\"Dataset/\"+folder+'/'+file)\n",
      "   9:         key = file.split('_')[-1].split('.')[0]\n",
      "  10:         label_name = label_dict[key]\n",
      "  11:     #img.resize(200,200)\n",
      "  12:         y.append(label_name)\n",
      "  13:         x.append(limg)\n",
      "  14:     return x,y    \n",
      "  15: path, dirs, files = next(os.walk(\"Dataset/train\"))\n",
      "  16: path, dirs2, files2 = next(os.walk(\"Dataset/test\"))\n",
      "  17: path, dirs3, files3 = next(os.walk(\"Dataset/validation\"))\n",
      "  18: \n",
      "  19: rx_train, ry_train = process_data(files,'train')\n",
      "  20: rx_test, ry_test = process_data(files2,'test')\n",
      "  21: rx_val, ry_val = process_data(files3,'validation')\n",
      "  22: \n",
      "  23: \n",
      "  24: x_train=np.array(rx_train).reshape(len(rx_train),34,34,1)\n",
      "  25: x_test=np.array(rx_test).reshape(len(rx_test),34,34,1)\n",
      "  26: x_val=np.array(rx_val).reshape(len(rx_val),34,34,1)\n",
      "  27: \n",
      "  28: X_train = np.array(x_train).astype('float32') / 255\n",
      "  29: X_test = np.array(x_test).astype('float32') / 255\n",
      "  30: X_val = np.array(x_val).astype('float32') / 255\n",
      "  31: Y_train = to_categorical(ry_train)\n",
      "  32: Y_test = to_categorical(ry_test)\n",
      "  33: Y_val = to_categorical(ry_val)\n",
      "  34: \n",
      "  35: \n",
      "  36: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     \n",
      "   4:     model = models.Sequential()\n",
      "   5:     model_choice = space['model_choice']\n",
      "   6:     if model_choice == 'one':\n",
      "   7:         model.add(layers.Conv2D(16, kernel_size=3, activation='relu',padding='same', input_shape=(34,34,1)))\n",
      "   8:         model.add(layers.Conv2D(16, kernel_size=3, activation='relu',padding='same'))\n",
      "   9:         model.add(layers.MaxPooling2D(pool_size=2,strides=2))\n",
      "  10:         model.add(layers.Dropout(space['Dropout']))\n",
      "  11: \n",
      "  12:         model.add(layers.Conv2D(32, kernel_size=3, activation='relu'))\n",
      "  13:         model.add(layers.Conv2D(32, kernel_size=3, activation='relu'))\n",
      "  14:         model.add(layers.BatchNormalization())\n",
      "  15:         model.add(layers.MaxPooling2D(pool_size=2,strides=2))\n",
      "  16:         model.add(layers.Dropout(space['Dropout_1']))\n",
      "  17:     elif model_choice == 'two':\n",
      "  18:         model.add(layers.Conv2D(32, kernel_size=3, activation='relu',padding='same', input_shape=(34,34,1)))\n",
      "  19:         model.add(layers.Conv2D(32, kernel_size=3, activation='relu',padding='same'))\n",
      "  20:         model.add(layers.MaxPooling2D(pool_size=2,strides=2))\n",
      "  21:         model.add(layers.Dropout(space['Dropout_2']))\n",
      "  22: \n",
      "  23:         model.add(layers.Conv2D(64, kernel_size=3, activation='relu'))\n",
      "  24:         model.add(layers.Conv2D(64, kernel_size=3, activation='relu'))\n",
      "  25:         model.add(layers.BatchNormalization())\n",
      "  26:         model.add(layers.MaxPooling2D(pool_size=2,strides=2))\n",
      "  27:         model.add(layers.Dropout(space['Dropout_3']))\n",
      "  28:     \n",
      "  29:     model.add(layers.Flatten())\n",
      "  30:     model.add(layers.Dense(space['Dense'], activation='relu'))\n",
      "  31:     model.add(layers.BatchNormalization())\n",
      "  32:     model.add(layers.Dropout(space['Dropout_4']))\n",
      "  33:     choiceval = space['model_choice_1']\n",
      "  34:     if choiceval == 'two':\n",
      "  35:         model.add(layers.Dense(space['Dense_1'], activation='relu'))\n",
      "  36:         model.add(layers.BatchNormalization())\n",
      "  37:         model.add(layers.Dropout(space['Dropout_5']))\n",
      "  38:     \n",
      "  39:     model.add(layers.Dense(11, activation='softmax'))\n",
      "  40:     \n",
      "  41:     adam = keras.optimizers.Adam(lr=0.001)\n",
      "  42:     \n",
      "  43:     model.compile(loss='categorical_crossentropy', metrics=['accuracy'],\n",
      "  44:                   optimizer=adam)\n",
      "  45: \n",
      "  46:     model.fit(X_train, Y_train,\n",
      "  47:               batch_size=128,\n",
      "  48:               nb_epoch=20,\n",
      "  49:               verbose=2,\n",
      "  50:               validation_data=(X_val, Y_val))\n",
      "  51:     score, acc = model.evaluate(X_val, Y_val, verbose=0)\n",
      "  52:     print('Val accuracy:', acc)\n",
      "  53:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
      "  54: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ovid2\\Documents\\AI\\temp_model.py:158: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13200 samples, validate on 4294 samples\n",
      "Epoch 1/20\n",
      " - 85s - loss: 2.4245 - acc: 0.3645 - val_loss: 1.3911 - val_acc: 0.5373\n",
      "Epoch 2/20\n",
      " - 86s - loss: 1.5295 - acc: 0.5052 - val_loss: 1.2750 - val_acc: 0.5484\n",
      "Epoch 3/20\n",
      " - 85s - loss: 1.2569 - acc: 0.5690 - val_loss: 1.1411 - val_acc: 0.5941\n",
      "Epoch 4/20\n",
      " - 86s - loss: 1.1066 - acc: 0.6068 - val_loss: 1.0906 - val_acc: 0.6109\n",
      "Epoch 5/20\n",
      " - 86s - loss: 0.9970 - acc: 0.6405 - val_loss: 0.9821 - val_acc: 0.6551\n",
      "Epoch 6/20\n",
      " - 85s - loss: 0.9031 - acc: 0.6747 - val_loss: 1.0173 - val_acc: 0.6493\n",
      "Epoch 7/20\n",
      " - 85s - loss: 0.8203 - acc: 0.7079 - val_loss: 0.8855 - val_acc: 0.7024\n",
      "Epoch 8/20\n",
      " - 84s - loss: 0.7428 - acc: 0.7394 - val_loss: 0.7855 - val_acc: 0.7331\n",
      "Epoch 9/20\n",
      " - 84s - loss: 0.6898 - acc: 0.7519 - val_loss: 0.7551 - val_acc: 0.7445\n",
      "Epoch 10/20\n",
      " - 86s - loss: 0.6478 - acc: 0.7767 - val_loss: 0.6197 - val_acc: 0.7944\n",
      "Epoch 11/20\n",
      " - 85s - loss: 0.6236 - acc: 0.7790 - val_loss: 0.6296 - val_acc: 0.7902\n",
      "Epoch 12/20\n",
      " - 86s - loss: 0.5924 - acc: 0.7917 - val_loss: 0.6041 - val_acc: 0.7997\n",
      "Epoch 13/20\n",
      " - 87s - loss: 0.5619 - acc: 0.8074 - val_loss: 0.5624 - val_acc: 0.8160\n",
      "Epoch 14/20\n",
      " - 88s - loss: 0.5471 - acc: 0.8100 - val_loss: 0.5762 - val_acc: 0.8125\n",
      "Epoch 15/20\n",
      " - 86s - loss: 0.5333 - acc: 0.8182 - val_loss: 0.5760 - val_acc: 0.8135\n",
      "Epoch 16/20\n",
      " - 85s - loss: 0.5135 - acc: 0.8248 - val_loss: 0.5364 - val_acc: 0.8337\n",
      "Epoch 17/20\n",
      " - 85s - loss: 0.4892 - acc: 0.8342 - val_loss: 0.5408 - val_acc: 0.8279\n",
      "Epoch 18/20\n",
      " - 86s - loss: 0.4899 - acc: 0.8365 - val_loss: 0.5216 - val_acc: 0.8323\n",
      "Epoch 19/20\n",
      " - 84s - loss: 0.4641 - acc: 0.8461 - val_loss: 0.4880 - val_acc: 0.8414\n",
      "Epoch 20/20\n",
      " - 85s - loss: 0.4568 - acc: 0.8476 - val_loss: 0.4795 - val_acc: 0.8496\n",
      "Val accuracy: 0.849557522096132\n",
      "Train on 13200 samples, validate on 4294 samples\n",
      "Epoch 1/20\n",
      " - 48s - loss: 4.3244 - acc: 0.1123 - val_loss: 1.8912 - val_acc: 0.3428\n",
      "Epoch 2/20\n",
      " - 46s - loss: 3.1020 - acc: 0.1568 - val_loss: 1.7752 - val_acc: 0.3973\n",
      "Epoch 3/20\n",
      " - 47s - loss: 2.5004 - acc: 0.1959 - val_loss: 1.8486 - val_acc: 0.3680\n",
      "Epoch 4/20\n",
      " - 43s - loss: 2.1716 - acc: 0.2222 - val_loss: 1.7092 - val_acc: 0.4227\n",
      "Epoch 5/20\n",
      " - 47s - loss: 1.9979 - acc: 0.2592 - val_loss: 1.7632 - val_acc: 0.3773\n",
      "Epoch 6/20\n",
      " - 47s - loss: 1.8991 - acc: 0.2850 - val_loss: 1.6953 - val_acc: 0.3933\n",
      "Epoch 7/20\n",
      " - 45s - loss: 1.8278 - acc: 0.3008 - val_loss: 1.6225 - val_acc: 0.4374\n",
      "Epoch 8/20\n",
      " - 47s - loss: 1.7882 - acc: 0.3205 - val_loss: 1.6567 - val_acc: 0.4199\n",
      "Epoch 9/20\n",
      " - 48s - loss: 1.7458 - acc: 0.3355 - val_loss: 1.6480 - val_acc: 0.4031\n",
      "Epoch 10/20\n",
      " - 47s - loss: 1.7141 - acc: 0.3512 - val_loss: 1.5460 - val_acc: 0.4679\n",
      "Epoch 11/20\n",
      " - 47s - loss: 1.6799 - acc: 0.3636 - val_loss: 1.5766 - val_acc: 0.4360\n",
      "Epoch 12/20\n",
      " - 47s - loss: 1.6577 - acc: 0.3699 - val_loss: 1.5275 - val_acc: 0.4469\n",
      "Epoch 13/20\n",
      " - 48s - loss: 1.6266 - acc: 0.3783 - val_loss: 1.3578 - val_acc: 0.5252\n",
      "Epoch 14/20\n",
      " - 48s - loss: 1.6006 - acc: 0.3865 - val_loss: 1.3235 - val_acc: 0.5396\n",
      "Epoch 15/20\n",
      " - 48s - loss: 1.5782 - acc: 0.3919 - val_loss: 1.3277 - val_acc: 0.5517\n",
      "Epoch 16/20\n",
      " - 48s - loss: 1.5699 - acc: 0.3912 - val_loss: 1.2979 - val_acc: 0.5475\n",
      "Epoch 17/20\n",
      " - 48s - loss: 1.5384 - acc: 0.4075 - val_loss: 1.3062 - val_acc: 0.5505\n",
      "Epoch 18/20\n",
      " - 48s - loss: 1.5274 - acc: 0.4081 - val_loss: 1.3732 - val_acc: 0.4793\n",
      "Epoch 19/20\n",
      " - 48s - loss: 1.4989 - acc: 0.4203 - val_loss: 1.2385 - val_acc: 0.5845\n",
      "Epoch 20/20\n",
      " - 48s - loss: 1.4965 - acc: 0.4221 - val_loss: 1.2404 - val_acc: 0.5617\n",
      "Val accuracy: 0.5617140195621798\n",
      "Train on 13200 samples, validate on 4294 samples\n",
      "Epoch 1/20\n",
      " - 51s - loss: 2.8656 - acc: 0.0955 - val_loss: 2.3711 - val_acc: 0.1272\n",
      "Epoch 2/20\n",
      " - 49s - loss: 2.6416 - acc: 0.0992 - val_loss: 2.3383 - val_acc: 0.2543\n",
      "Epoch 3/20\n",
      " - 45s - loss: 2.5492 - acc: 0.1108 - val_loss: 2.2826 - val_acc: 0.2636\n",
      "Epoch 4/20\n",
      " - 49s - loss: 2.4762 - acc: 0.1181 - val_loss: 2.2149 - val_acc: 0.2599\n",
      "Epoch 5/20\n",
      " - 49s - loss: 2.4064 - acc: 0.1317 - val_loss: 2.1602 - val_acc: 0.2918\n",
      "Epoch 6/20\n",
      " - 45s - loss: 2.3427 - acc: 0.1392 - val_loss: 2.0900 - val_acc: 0.2976\n",
      "Epoch 7/20\n",
      " - 48s - loss: 2.3008 - acc: 0.1510 - val_loss: 2.0511 - val_acc: 0.3088\n",
      "Epoch 8/20\n",
      " - 53s - loss: 2.2683 - acc: 0.1511 - val_loss: 2.0103 - val_acc: 0.2981\n",
      "Epoch 9/20\n",
      " - 40s - loss: 2.2197 - acc: 0.1635 - val_loss: 1.9962 - val_acc: 0.3007\n",
      "Epoch 10/20\n",
      " - 40s - loss: 2.1887 - acc: 0.1667 - val_loss: 1.9429 - val_acc: 0.3095\n",
      "Epoch 11/20\n",
      " - 40s - loss: 2.1593 - acc: 0.1727 - val_loss: 1.9047 - val_acc: 0.3237\n",
      "Epoch 12/20\n",
      " - 39s - loss: 2.1506 - acc: 0.1809 - val_loss: 1.9038 - val_acc: 0.2937\n",
      "Epoch 13/20\n",
      " - 41s - loss: 2.1165 - acc: 0.1800 - val_loss: 1.8391 - val_acc: 0.3204\n",
      "Epoch 14/20\n",
      " - 39s - loss: 2.1054 - acc: 0.1728 - val_loss: 1.8935 - val_acc: 0.2820\n",
      "Epoch 15/20\n",
      " - 39s - loss: 2.0927 - acc: 0.1882 - val_loss: 1.8180 - val_acc: 0.3097\n",
      "Epoch 16/20\n",
      " - 42s - loss: 2.0928 - acc: 0.1756 - val_loss: 1.8224 - val_acc: 0.3020\n",
      "Epoch 17/20\n",
      " - 39s - loss: 2.0674 - acc: 0.1830 - val_loss: 1.8049 - val_acc: 0.3186\n",
      "Epoch 18/20\n",
      " - 42s - loss: 2.0636 - acc: 0.1864 - val_loss: 1.7770 - val_acc: 0.2890\n",
      "Epoch 19/20\n",
      " - 43s - loss: 2.0476 - acc: 0.1910 - val_loss: 1.7827 - val_acc: 0.2613\n",
      "Epoch 20/20\n",
      " - 39s - loss: 2.0505 - acc: 0.1895 - val_loss: 1.8093 - val_acc: 0.2976\n",
      "Val accuracy: 0.2976245924545878\n",
      "Train on 13200 samples, validate on 4294 samples\n",
      "Epoch 1/20\n",
      " - 78s - loss: 2.7788 - acc: 0.1881 - val_loss: 2.7300 - val_acc: 0.0904\n",
      "Epoch 2/20\n",
      " - 77s - loss: 2.0528 - acc: 0.2969 - val_loss: 2.8661 - val_acc: 0.0908\n",
      "Epoch 3/20\n",
      " - 76s - loss: 1.7829 - acc: 0.3573 - val_loss: 2.6841 - val_acc: 0.0908\n",
      "Epoch 4/20\n",
      " - 80s - loss: 1.6197 - acc: 0.3982 - val_loss: 2.6741 - val_acc: 0.0908\n",
      "Epoch 5/20\n",
      " - 77s - loss: 1.5237 - acc: 0.4293 - val_loss: 2.5649 - val_acc: 0.1379\n",
      "Epoch 6/20\n",
      " - 81s - loss: 1.4518 - acc: 0.4507 - val_loss: 2.6163 - val_acc: 0.0908\n",
      "Epoch 7/20\n",
      " - 78s - loss: 1.3815 - acc: 0.4802 - val_loss: 2.6665 - val_acc: 0.0908\n",
      "Epoch 8/20\n",
      " - 77s - loss: 1.3470 - acc: 0.4886 - val_loss: 2.7412 - val_acc: 0.0908\n",
      "Epoch 9/20\n",
      " - 78s - loss: 1.2863 - acc: 0.5067 - val_loss: 2.8001 - val_acc: 0.0908\n",
      "Epoch 10/20\n",
      " - 78s - loss: 1.2419 - acc: 0.5271 - val_loss: 2.7551 - val_acc: 0.0908\n",
      "Epoch 11/20\n",
      " - 77s - loss: 1.2091 - acc: 0.5388 - val_loss: 2.7962 - val_acc: 0.0915\n",
      "Epoch 12/20\n",
      " - 78s - loss: 1.1874 - acc: 0.5468 - val_loss: 2.8448 - val_acc: 0.0908\n",
      "Epoch 13/20\n",
      " - 77s - loss: 1.1568 - acc: 0.5558 - val_loss: 2.8085 - val_acc: 0.0915\n",
      "Epoch 14/20\n",
      " - 61s - loss: 1.1482 - acc: 0.5588 - val_loss: 2.8335 - val_acc: 0.0911\n",
      "Epoch 15/20\n",
      " - 59s - loss: 1.1170 - acc: 0.5717 - val_loss: 2.9086 - val_acc: 0.0908\n",
      "Epoch 16/20\n",
      " - 60s - loss: 1.0963 - acc: 0.5764 - val_loss: 2.8714 - val_acc: 0.0894\n",
      "Epoch 17/20\n",
      " - 60s - loss: 1.0959 - acc: 0.5817 - val_loss: 2.8442 - val_acc: 0.0932\n",
      "Epoch 18/20\n",
      " - 60s - loss: 1.0666 - acc: 0.5910 - val_loss: 2.8675 - val_acc: 0.1006\n",
      "Epoch 19/20\n",
      " - 61s - loss: 1.0529 - acc: 0.6033 - val_loss: 2.7721 - val_acc: 0.0959\n",
      "Epoch 20/20\n",
      " - 59s - loss: 1.0464 - acc: 0.5997 - val_loss: 2.7986 - val_acc: 0.1155\n",
      "Val accuracy: 0.11551001397298556\n",
      "Train on 13200 samples, validate on 4294 samples\n",
      "Epoch 1/20\n",
      " - 32s - loss: 3.3071 - acc: 0.1126 - val_loss: 2.6000 - val_acc: 0.0913\n",
      "Epoch 2/20\n",
      " - 30s - loss: 2.5970 - acc: 0.1578 - val_loss: 2.4272 - val_acc: 0.1169\n",
      "Epoch 3/20\n",
      " - 31s - loss: 2.1645 - acc: 0.2392 - val_loss: 2.2388 - val_acc: 0.1819\n",
      "Epoch 4/20\n",
      " - 30s - loss: 1.9358 - acc: 0.2900 - val_loss: 2.0778 - val_acc: 0.2163\n",
      "Epoch 5/20\n",
      " - 30s - loss: 1.7785 - acc: 0.3395 - val_loss: 1.9223 - val_acc: 0.2555\n",
      "Epoch 6/20\n",
      " - 30s - loss: 1.6742 - acc: 0.3595 - val_loss: 1.7473 - val_acc: 0.3195\n",
      "Epoch 7/20\n",
      " - 30s - loss: 1.5689 - acc: 0.3983 - val_loss: 1.7027 - val_acc: 0.3531\n",
      "Epoch 8/20\n",
      " - 31s - loss: 1.5064 - acc: 0.4172 - val_loss: 1.5681 - val_acc: 0.3959\n",
      "Epoch 9/20\n",
      " - 30s - loss: 1.4531 - acc: 0.4398 - val_loss: 1.6501 - val_acc: 0.3621\n",
      "Epoch 10/20\n",
      " - 30s - loss: 1.4048 - acc: 0.4583 - val_loss: 1.6926 - val_acc: 0.3612\n",
      "Epoch 11/20\n",
      " - 31s - loss: 1.3632 - acc: 0.4823 - val_loss: 1.7349 - val_acc: 0.3472\n",
      "Epoch 12/20\n",
      " - 30s - loss: 1.3408 - acc: 0.4893 - val_loss: 1.7608 - val_acc: 0.3510\n",
      "Epoch 13/20\n",
      " - 30s - loss: 1.3208 - acc: 0.4951 - val_loss: 1.7548 - val_acc: 0.3582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      " - 30s - loss: 1.2941 - acc: 0.5019 - val_loss: 1.6832 - val_acc: 0.3861\n",
      "Epoch 15/20\n",
      " - 30s - loss: 1.2676 - acc: 0.5096 - val_loss: 1.8369 - val_acc: 0.3526\n",
      "Epoch 16/20\n",
      " - 30s - loss: 1.2709 - acc: 0.5124 - val_loss: 1.6281 - val_acc: 0.3847\n",
      "Epoch 17/20\n",
      " - 30s - loss: 1.2511 - acc: 0.5179 - val_loss: 1.7857 - val_acc: 0.3549\n",
      "Epoch 18/20\n",
      " - 33s - loss: 1.2370 - acc: 0.5264 - val_loss: 1.9430 - val_acc: 0.3328\n",
      "Epoch 19/20\n",
      " - 30s - loss: 1.2210 - acc: 0.5283 - val_loss: 1.9165 - val_acc: 0.3260\n",
      "Epoch 20/20\n",
      " - 32s - loss: 1.2119 - acc: 0.5353 - val_loss: 2.1104 - val_acc: 0.2764\n",
      "Val accuracy: 0.2764322310269684\n",
      "Train on 13200 samples, validate on 4294 samples\n",
      "Epoch 1/20\n",
      " - 64s - loss: 3.2698 - acc: 0.1746 - val_loss: 1.5413 - val_acc: 0.4558\n",
      "Epoch 2/20\n",
      " - 60s - loss: 2.2333 - acc: 0.2933 - val_loss: 1.5431 - val_acc: 0.4390\n",
      "Epoch 3/20\n",
      " - 64s - loss: 1.8235 - acc: 0.3579 - val_loss: 1.5437 - val_acc: 0.4432\n",
      "Epoch 4/20\n",
      " - 63s - loss: 1.5689 - acc: 0.4166 - val_loss: 1.3263 - val_acc: 0.5210\n",
      "Epoch 5/20\n",
      " - 62s - loss: 1.4581 - acc: 0.4572 - val_loss: 1.3091 - val_acc: 0.5200\n",
      "Epoch 6/20\n",
      " - 59s - loss: 1.3605 - acc: 0.4893 - val_loss: 1.3388 - val_acc: 0.4986\n",
      "Epoch 7/20\n",
      " - 59s - loss: 1.2928 - acc: 0.5098 - val_loss: 1.5406 - val_acc: 0.4252\n",
      "Epoch 8/20\n",
      " - 59s - loss: 1.2486 - acc: 0.5302 - val_loss: 1.1363 - val_acc: 0.5838\n",
      "Epoch 9/20\n",
      " - 59s - loss: 1.1918 - acc: 0.5483 - val_loss: 1.2523 - val_acc: 0.5366\n",
      "Epoch 10/20\n",
      " - 60s - loss: 1.1562 - acc: 0.5684 - val_loss: 1.0423 - val_acc: 0.6020\n",
      "Epoch 11/20\n",
      " - 59s - loss: 1.1176 - acc: 0.5814 - val_loss: 1.0009 - val_acc: 0.6074\n",
      "Epoch 12/20\n",
      " - 58s - loss: 1.0705 - acc: 0.5957 - val_loss: 0.9488 - val_acc: 0.6646\n",
      "Epoch 13/20\n",
      " - 59s - loss: 1.0550 - acc: 0.6111 - val_loss: 0.9390 - val_acc: 0.6619\n",
      "Epoch 14/20\n",
      " - 59s - loss: 1.0226 - acc: 0.6251 - val_loss: 0.9145 - val_acc: 0.6658\n",
      "Epoch 15/20\n",
      " - 59s - loss: 0.9931 - acc: 0.6363 - val_loss: 0.9188 - val_acc: 0.6619\n",
      "Epoch 16/20\n",
      " - 59s - loss: 0.9540 - acc: 0.6490 - val_loss: 0.9287 - val_acc: 0.6402\n",
      "Epoch 17/20\n",
      " - 59s - loss: 0.9594 - acc: 0.6530 - val_loss: 0.7844 - val_acc: 0.7217\n",
      "Epoch 18/20\n",
      " - 59s - loss: 0.9318 - acc: 0.6659 - val_loss: 0.7332 - val_acc: 0.7438\n",
      "Epoch 19/20\n",
      " - 59s - loss: 0.8851 - acc: 0.6764 - val_loss: 0.7431 - val_acc: 0.7347\n",
      "Epoch 20/20\n",
      " - 58s - loss: 0.8822 - acc: 0.6832 - val_loss: 0.8633 - val_acc: 0.6602\n",
      "Val accuracy: 0.6602235677412182\n",
      "Train on 13200 samples, validate on 4294 samples\n",
      "Epoch 1/20\n",
      " - 60s - loss: 1.3462 - acc: 0.5344 - val_loss: 1.0469 - val_acc: 0.6397\n",
      "Epoch 2/20\n",
      " - 62s - loss: 0.7154 - acc: 0.7461 - val_loss: 0.7103 - val_acc: 0.7534\n",
      "Epoch 3/20\n",
      " - 59s - loss: 0.5068 - acc: 0.8277 - val_loss: 0.6315 - val_acc: 0.7874\n",
      "Epoch 4/20\n",
      " - 58s - loss: 0.4137 - acc: 0.8602 - val_loss: 0.4514 - val_acc: 0.8486\n",
      "Epoch 5/20\n",
      " - 59s - loss: 0.3515 - acc: 0.8833 - val_loss: 0.4239 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      " - 58s - loss: 0.3114 - acc: 0.8995 - val_loss: 0.3772 - val_acc: 0.8777\n",
      "Epoch 7/20\n",
      " - 60s - loss: 0.2741 - acc: 0.9103 - val_loss: 0.3643 - val_acc: 0.8819\n",
      "Epoch 8/20\n",
      " - 61s - loss: 0.2496 - acc: 0.9210 - val_loss: 0.3906 - val_acc: 0.8756\n",
      "Epoch 9/20\n",
      " - 64s - loss: 0.2340 - acc: 0.9245 - val_loss: 0.3235 - val_acc: 0.8982\n",
      "Epoch 10/20\n",
      " - 63s - loss: 0.2156 - acc: 0.9308 - val_loss: 0.4274 - val_acc: 0.8654\n",
      "Epoch 11/20\n",
      " - 59s - loss: 0.2093 - acc: 0.9320 - val_loss: 0.3327 - val_acc: 0.9010\n",
      "Epoch 12/20\n",
      " - 59s - loss: 0.1941 - acc: 0.9352 - val_loss: 0.3422 - val_acc: 0.8903\n",
      "Epoch 13/20\n",
      " - 60s - loss: 0.1902 - acc: 0.9377 - val_loss: 0.3041 - val_acc: 0.9050\n",
      "Epoch 14/20\n",
      " - 60s - loss: 0.1632 - acc: 0.9475 - val_loss: 0.3171 - val_acc: 0.9031\n",
      "Epoch 15/20\n",
      " - 60s - loss: 0.1683 - acc: 0.9472 - val_loss: 0.2796 - val_acc: 0.9143\n",
      "Epoch 16/20\n",
      " - 60s - loss: 0.1416 - acc: 0.9556 - val_loss: 0.2805 - val_acc: 0.9148\n",
      "Epoch 17/20\n",
      " - 60s - loss: 0.1465 - acc: 0.9530 - val_loss: 0.2733 - val_acc: 0.9143\n",
      "Epoch 18/20\n",
      " - 60s - loss: 0.1421 - acc: 0.9521 - val_loss: 0.2680 - val_acc: 0.9171\n",
      "Epoch 19/20\n",
      " - 60s - loss: 0.1274 - acc: 0.9575 - val_loss: 0.2823 - val_acc: 0.9136\n",
      "Epoch 20/20\n",
      " - 60s - loss: 0.1297 - acc: 0.9566 - val_loss: 0.2714 - val_acc: 0.9194\n",
      "Val accuracy: 0.9194224499301351\n",
      "Train on 13200 samples, validate on 4294 samples\n",
      "Epoch 1/20\n",
      " - 64s - loss: 1.4730 - acc: 0.5090 - val_loss: 1.0024 - val_acc: 0.6549\n",
      "Epoch 2/20\n",
      " - 62s - loss: 0.7827 - acc: 0.7219 - val_loss: 0.7073 - val_acc: 0.7646\n",
      "Epoch 3/20\n",
      " - 59s - loss: 0.5541 - acc: 0.8058 - val_loss: 0.5943 - val_acc: 0.8009\n",
      "Epoch 4/20\n"
     ]
    }
   ],
   "source": [
    "%run OptimizingCNN.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Conclusion\n",
    "Although there exists more than 50 characters in Bangla language, this dataset is relatively small than this. To make a better classifier, it is necessary to upgrade this dataset.\n",
    "Model ensembling can change the classification rate. TensorBoard is a great way to visualize model activity in the browser. Anyone can use it in Keras models via the TensorBoard callback.\n",
    "There is a number of keras function API to build advance neural network model. In future, I will incorporate it in my model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Reference\n",
    "\n",
    "1. https://data.mendeley.com/datasets/hf6sf8zrkc/2\n",
    "2. https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python\n",
    "3. https://towardsdatascience.com/a-guide-to-an-efficient-way-to-build-neural-network-architectures-part-i-hyper-parameter-8129009f131b?fbclid=IwAR1TcWxidpqvCaxAxH6KFZOMQw9PnbOBHjIe71at-jVSedBpyxV052ToSFk\n",
    "4. https://stackoverflow.com/questions/20186344/ipynb-import-another-ipynb-file\n",
    "5. https://keras.rstudio.com/reference/layer_depthwise_conv_2d.html\n",
    "6. https://docgo.net/viewdoc.html?utm_source=dropbox-chollet-pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
