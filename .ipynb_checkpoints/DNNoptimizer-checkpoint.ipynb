{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "from skimage.transform import resize \n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from keras.utils import to_categorical\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "\n",
    "from keras import backend as k\n",
    "\n",
    "k.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    def process_data(files,folder):\n",
    "        from skimage import data\n",
    "        label_dict={'1':'0','2':'1','3':'2','4':'3','5':'4','6':'5','7':'6','8':'7','9':'8','10':'9','11':'10'}\n",
    "        x=[]\n",
    "        y=[]\n",
    "        for file in files:\n",
    "            limg= data.imread(\"Dataset/\"+folder+'/'+file)\n",
    "            key = file.split('_')[-1].split('.')[0]\n",
    "            label_name = label_dict[key]\n",
    "        #img.resize(200,200)\n",
    "            y.append(label_name)\n",
    "            x.append(limg)\n",
    "        return x,y    \n",
    "    path, dirs, files = next(os.walk(\"Dataset/train\"))\n",
    "    path, dirs2, files2 = next(os.walk(\"Dataset/test\"))\n",
    "    path, dirs3, files3 = next(os.walk(\"Dataset/validation\"))\n",
    "    \n",
    "    rx_train, ry_train = process_data(files,'train')\n",
    "    rx_test, ry_test = process_data(files2,'test')\n",
    "    rx_val, ry_val = process_data(files3,'validation')\n",
    "\n",
    "\n",
    "    x_train=np.array(rx_train).reshape(len(rx_train),34,34,1)\n",
    "    x_test=np.array(rx_test).reshape(len(rx_test),34,34,1)\n",
    "    x_val=np.array(rx_val).reshape(len(rx_val),34,34,1)\n",
    "\n",
    "    X_train = np.array(x_train).astype('float32') / 255\n",
    "    X_test = np.array(x_test).astype('float32') / 255\n",
    "    X_val = np.array(x_val).astype('float32') / 255\n",
    "    Y_train = to_categorical(ry_train)\n",
    "    Y_test = to_categorical(ry_test)\n",
    "    Y_val = to_categorical(ry_val)\n",
    "    return X_train, Y_train, X_val, Y_val,X_test,Y_test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read image data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_val, Y_val):\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense({{choice([128, 256, 512, 1024])}}, input_shape=(34*34,)))\n",
    "    model.add(layers.Activation({{choice(['relu', 'sigmoid'])}}))\n",
    "    model.add(layers.Dropout({{uniform(0, 1)}}))\n",
    "    model.add(layers.Dense({{choice([128, 256, 512, 1024])}}))\n",
    "    model.add(layers.Activation({{choice(['relu', 'sigmoid'])}}))\n",
    "    model.add(layers.Dropout({{uniform(0, 1)}}))\n",
    "    \n",
    "    if conditional({{choice(['two', 'three'])}}) == 'three':\n",
    "        model.add(layers.Dense({{choice([128, 256, 512, 1024])}}))\n",
    "        model.add(layers.Activation({{choice(['relu', 'sigmoid'])}}))\n",
    "        model.add(layers.Dropout({{uniform(0, 1)}}))\n",
    "        \n",
    "\n",
    "    model.add(layers.Dense(11))\n",
    "    model.add(layers.Activation('softmax'))\n",
    "\n",
    "    adam = keras.optimizers.Adam(lr={{choice([10**-3, 10**-2, 10**-1])}})\n",
    "    rmsprop = keras.optimizers.RMSprop(lr={{choice([10**-3, 10**-2, 10**-1])}})\n",
    "    sgd = keras.optimizers.SGD(lr={{choice([10**-3, 10**-2, 10**-1])}})\n",
    "   \n",
    "    choiceval = {{choice(['adam', 'sgd', 'rmsprop'])}}\n",
    "    if choiceval == 'adam':\n",
    "        optim = adam\n",
    "    elif choiceval == 'rmsprop':\n",
    "        optim = rmsprop\n",
    "    else:\n",
    "        optim = sgd\n",
    "        \n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=optim)\n",
    "\n",
    "    model.fit(X_train, Y_train,\n",
    "              batch_size={{choice([128,256,512])}},\n",
    "              nb_epoch=20,\n",
    "              verbose=2,\n",
    "              validation_data=(X_val, Y_val))\n",
    "    score, acc = model.evaluate(X_val, Y_val, verbose=0)\n",
    "    print('Test accuracy:', acc)\n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import os, shutil\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from skimage.transform import resize\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from matplotlib import pyplot\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import to_categorical\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import keras\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import layers\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import models\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend as k\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from skimage import data\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Dense': hp.choice('Dense', [128, 256, 512, 1024]),\n",
      "        'Activation': hp.choice('Activation', ['relu', 'softmax']),\n",
      "        'Dropout': hp.uniform('Dropout', 0, 1),\n",
      "        'Dense_1': hp.choice('Dense_1', [128, 256, 512, 1024]),\n",
      "        'Activation_1': hp.choice('Activation_1', ['relu', 'sigmoid']),\n",
      "        'Dropout_1': hp.uniform('Dropout_1', 0, 1),\n",
      "        'conditional': hp.choice('conditional', ['two', 'three']),\n",
      "        'Dense_2': hp.choice('Dense_2', [128, 256, 512, 1024]),\n",
      "        'Activation_2': hp.choice('Activation_2', ['relu', 'sigmoid']),\n",
      "        'Dropout_2': hp.uniform('Dropout_2', 0, 1),\n",
      "        'lr': hp.choice('lr', [10**-3, 10**-2, 10**-1]),\n",
      "        'lr_1': hp.choice('lr_1', [10**-3, 10**-2, 10**-1]),\n",
      "        'lr_2': hp.choice('lr_2', [10**-3, 10**-2, 10**-1]),\n",
      "        'choiceval': hp.choice('choiceval', ['adam', 'sgd', 'rmsprop']),\n",
      "        'batch_size': hp.choice('batch_size', [128,256,512]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "   1: \n",
      "   2: def process_data(files,folder):\n",
      "   3:     from skimage import data\n",
      "   4:     label_dict={'1':'0','2':'1','3':'2','4':'3','5':'4','6':'5','7':'6','8':'7','9':'8','10':'9','11':'10'}\n",
      "   5:     x=[]\n",
      "   6:     y=[]\n",
      "   7:     for file in files:\n",
      "   8:         limg= data.imread(\"Dataset/\"+folder+'/'+file)\n",
      "   9:         key = file.split('_')[-1].split('.')[0]\n",
      "  10:         label_name = label_dict[key]\n",
      "  11:     #img.resize(200,200)\n",
      "  12:         y.append(label_name)\n",
      "  13:         x.append(limg)\n",
      "  14:     return x,y    \n",
      "  15: path, dirs, files = next(os.walk(\"Dataset/train\"))\n",
      "  16: path, dirs2, files2 = next(os.walk(\"Dataset/test\"))\n",
      "  17: path, dirs3, files3 = next(os.walk(\"Dataset/validation\"))\n",
      "  18: \n",
      "  19: rx_train, ry_train = process_data(files,'train')\n",
      "  20: rx_test, ry_test = process_data(files2,'test')\n",
      "  21: rx_val, ry_val = process_data(files3,'validation')\n",
      "  22: \n",
      "  23: \n",
      "  24: x_train=np.array(rx_train).reshape(11000,34*34)\n",
      "  25: x_test=np.array(rx_test).reshape(5335,34*34)\n",
      "  26: x_val=np.array(rx_val).reshape(5335,34*34)\n",
      "  27: \n",
      "  28: X_train = np.array(x_train).astype('float32') / 255\n",
      "  29: X_test = np.array(x_test).astype('float32') / 255\n",
      "  30: X_val = np.array(x_val).astype('float32') / 255\n",
      "  31: Y_train = to_categorical(ry_train)\n",
      "  32: Y_test = to_categorical(ry_test)\n",
      "  33: Y_val = to_categorical(ry_val)\n",
      "  34: \n",
      "  35: \n",
      "  36: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     \n",
      "   4:     model = models.Sequential()\n",
      "   5:     model.add(layers.Dense(space['Dense'], input_shape=(34*34,)))\n",
      "   6:     model.add(layers.Activation(space['Activation']))\n",
      "   7:     model.add(layers.Dropout(space['Dropout']))\n",
      "   8:     model.add(layers.Dense(space['Dense_1']))\n",
      "   9:     model.add(layers.Activation(space['Activation_1']))\n",
      "  10:     model.add(layers.Dropout(space['Dropout_1']))\n",
      "  11:     \n",
      "  12:     if conditional(space['conditional']) == 'three':\n",
      "  13:         model.add(layers.Dense(space['Dense_2']))\n",
      "  14:         model.add(layers.Activation(space['Activation_2']))\n",
      "  15:         model.add(layers.Dropout(space['Dropout_2']))\n",
      "  16:         \n",
      "  17: \n",
      "  18:     model.add(layers.Dense(11))\n",
      "  19:     model.add(layers.Activation('softmax'))\n",
      "  20: \n",
      "  21:     adam = keras.optimizers.Adam(lr=space['lr'])\n",
      "  22:     rmsprop = keras.optimizers.RMSprop(lr=space['lr_1'])\n",
      "  23:     sgd = keras.optimizers.SGD(lr=space['lr_2'])\n",
      "  24:    \n",
      "  25:     choiceval = space['choiceval']\n",
      "  26:     if choiceval == 'adam':\n",
      "  27:         optim = adam\n",
      "  28:     elif choiceval == 'rmsprop':\n",
      "  29:         optim = rmsprop\n",
      "  30:     else:\n",
      "  31:         optim = sgd\n",
      "  32:         \n",
      "  33:     model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=optim)\n",
      "  34: \n",
      "  35:     model.fit(X_train, Y_train,\n",
      "  36:               batch_size=space['batch_size'],\n",
      "  37:               nb_epoch=20,\n",
      "  38:               verbose=2,\n",
      "  39:               validation_data=(X_val, Y_val))\n",
      "  40:     score, acc = model.evaluate(X_val, Y_val, verbose=0)\n",
      "  41:     print('Test accuracy:', acc)\n",
      "  42:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
      "  43: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ovid2\\Documents\\AI\\temp_model.py:142: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11000 samples, validate on 5335 samples\n",
      "Epoch 1/20\n",
      " - 1s - loss: 2.3979 - acc: 0.0887 - val_loss: 2.3975 - val_acc: 0.0924\n",
      "Epoch 2/20\n",
      " - 1s - loss: 2.3978 - acc: 0.0901 - val_loss: 2.3975 - val_acc: 0.0954\n",
      "Epoch 3/20\n",
      " - 1s - loss: 2.3977 - acc: 0.0905 - val_loss: 2.3974 - val_acc: 0.1188\n",
      "Epoch 4/20\n",
      " - 1s - loss: 2.3977 - acc: 0.0980 - val_loss: 2.3974 - val_acc: 0.0911\n",
      "Epoch 5/20\n",
      " - 1s - loss: 2.3976 - acc: 0.0936 - val_loss: 2.3973 - val_acc: 0.1312\n",
      "Epoch 6/20\n",
      " - 1s - loss: 2.3976 - acc: 0.1025 - val_loss: 2.3973 - val_acc: 0.0909\n",
      "Epoch 7/20\n",
      " - 1s - loss: 2.3976 - acc: 0.0955 - val_loss: 2.3973 - val_acc: 0.1443\n",
      "Epoch 8/20\n",
      " - 1s - loss: 2.3976 - acc: 0.0997 - val_loss: 2.3972 - val_acc: 0.1475\n",
      "Epoch 9/20\n",
      " - 1s - loss: 2.3975 - acc: 0.0972 - val_loss: 2.3972 - val_acc: 0.1241\n",
      "Epoch 10/20\n",
      " - 1s - loss: 2.3975 - acc: 0.0974 - val_loss: 2.3972 - val_acc: 0.0913\n",
      "Epoch 11/20\n",
      " - 1s - loss: 2.3975 - acc: 0.1072 - val_loss: 2.3971 - val_acc: 0.0917\n",
      "Epoch 12/20\n",
      " - 1s - loss: 2.3975 - acc: 0.0984 - val_loss: 2.3971 - val_acc: 0.1246\n",
      "Epoch 13/20\n",
      " - 1s - loss: 2.3974 - acc: 0.1024 - val_loss: 2.3971 - val_acc: 0.1192\n",
      "Epoch 14/20\n",
      " - 1s - loss: 2.3974 - acc: 0.1032 - val_loss: 2.3970 - val_acc: 0.1095\n",
      "Epoch 15/20\n",
      " - 1s - loss: 2.3973 - acc: 0.0995 - val_loss: 2.3970 - val_acc: 0.1303\n",
      "Epoch 16/20\n",
      " - 1s - loss: 2.3972 - acc: 0.1053 - val_loss: 2.3969 - val_acc: 0.2007\n",
      "Epoch 17/20\n",
      " - 1s - loss: 2.3972 - acc: 0.1091 - val_loss: 2.3969 - val_acc: 0.0932\n",
      "Epoch 18/20\n",
      " - 1s - loss: 2.3972 - acc: 0.1015 - val_loss: 2.3969 - val_acc: 0.1183\n",
      "Epoch 19/20\n",
      " - 1s - loss: 2.3971 - acc: 0.1031 - val_loss: 2.3968 - val_acc: 0.1648\n",
      "Epoch 20/20\n",
      " - 1s - loss: 2.3971 - acc: 0.1109 - val_loss: 2.3968 - val_acc: 0.1850\n",
      "Test accuracy: 0.18500468600488984\n",
      "Train on 11000 samples, validate on 5335 samples\n",
      "Epoch 1/20\n",
      " - 2s - loss: 14.1959 - acc: 0.0892 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 2/20\n",
      " - 1s - loss: 14.6528 - acc: 0.0909 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 3/20\n",
      " - 1s - loss: 14.6528 - acc: 0.0909 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 4/20\n",
      " - 1s - loss: 14.6528 - acc: 0.0909 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 5/20\n",
      " - 1s - loss: 14.6528 - acc: 0.0909 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 6/20\n",
      " - 1s - loss: 14.6528 - acc: 0.0909 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 7/20\n",
      " - 1s - loss: 14.6528 - acc: 0.0909 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 8/20\n",
      " - 1s - loss: 14.6528 - acc: 0.0909 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 9/20\n",
      " - 1s - loss: 14.6528 - acc: 0.0909 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 10/20\n",
      " - 1s - loss: 14.6528 - acc: 0.0909 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 11/20\n",
      " - 1s - loss: 14.6528 - acc: 0.0909 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 12/20\n",
      " - 1s - loss: 14.6528 - acc: 0.0909 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 13/20\n",
      " - 1s - loss: 14.6528 - acc: 0.0909 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 14/20\n",
      " - 1s - loss: 14.6528 - acc: 0.0909 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 15/20\n",
      " - 1s - loss: 14.6528 - acc: 0.0909 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 16/20\n",
      " - 1s - loss: 14.6528 - acc: 0.0909 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 17/20\n",
      " - 1s - loss: 14.6528 - acc: 0.0909 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 18/20\n",
      " - 1s - loss: 14.6528 - acc: 0.0909 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 19/20\n",
      " - 1s - loss: 14.6528 - acc: 0.0909 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 20/20\n",
      " - 1s - loss: 14.6528 - acc: 0.0909 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Test accuracy: 0.09090909090909091\n",
      "Train on 11000 samples, validate on 5335 samples\n",
      "Epoch 1/20\n",
      " - 2s - loss: 2.9203 - acc: 0.0928 - val_loss: 2.4266 - val_acc: 0.0909\n",
      "Epoch 2/20\n",
      " - 1s - loss: 2.8596 - acc: 0.0935 - val_loss: 2.4061 - val_acc: 0.0909\n",
      "Epoch 3/20\n",
      " - 1s - loss: 2.8392 - acc: 0.0926 - val_loss: 2.4001 - val_acc: 0.0909\n",
      "Epoch 4/20\n",
      " - 1s - loss: 2.8439 - acc: 0.0878 - val_loss: 2.3986 - val_acc: 0.0909\n",
      "Epoch 5/20\n",
      " - 1s - loss: 2.8274 - acc: 0.0851 - val_loss: 2.3982 - val_acc: 0.0909\n",
      "Epoch 6/20\n",
      " - 1s - loss: 2.7970 - acc: 0.0935 - val_loss: 2.3982 - val_acc: 0.0909\n",
      "Epoch 7/20\n",
      " - 1s - loss: 2.8102 - acc: 0.0890 - val_loss: 2.3982 - val_acc: 0.0909\n",
      "Epoch 8/20\n",
      " - 1s - loss: 2.7966 - acc: 0.0906 - val_loss: 2.3982 - val_acc: 0.0917\n",
      "Epoch 9/20\n",
      " - 1s - loss: 2.7684 - acc: 0.0942 - val_loss: 2.3981 - val_acc: 0.1035\n",
      "Epoch 10/20\n",
      " - 1s - loss: 2.7745 - acc: 0.0897 - val_loss: 2.3982 - val_acc: 0.0909\n",
      "Epoch 11/20\n",
      " - 1s - loss: 2.7602 - acc: 0.0934 - val_loss: 2.3983 - val_acc: 0.0909\n",
      "Epoch 12/20\n",
      " - 1s - loss: 2.7519 - acc: 0.0905 - val_loss: 2.3981 - val_acc: 0.0909\n",
      "Epoch 13/20\n",
      " - 2s - loss: 2.7535 - acc: 0.0934 - val_loss: 2.3981 - val_acc: 0.0909\n",
      "Epoch 14/20\n",
      " - 1s - loss: 2.7424 - acc: 0.0920 - val_loss: 2.3981 - val_acc: 0.0909\n",
      "Epoch 15/20\n",
      " - 1s - loss: 2.7380 - acc: 0.0957 - val_loss: 2.3981 - val_acc: 0.0909\n",
      "Epoch 16/20\n",
      " - 1s - loss: 2.7285 - acc: 0.0916 - val_loss: 2.3981 - val_acc: 0.0909\n",
      "Epoch 17/20\n",
      " - 1s - loss: 2.7316 - acc: 0.0893 - val_loss: 2.3981 - val_acc: 0.0909\n",
      "Epoch 18/20\n",
      " - 1s - loss: 2.7178 - acc: 0.0886 - val_loss: 2.3980 - val_acc: 0.0909\n",
      "Epoch 19/20\n",
      " - 2s - loss: 2.7049 - acc: 0.0942 - val_loss: 2.3981 - val_acc: 0.0909\n",
      "Epoch 20/20\n",
      " - 2s - loss: 2.6863 - acc: 0.0924 - val_loss: 2.3981 - val_acc: 0.0909\n",
      "Test accuracy: 0.09090909090909091\n",
      "Train on 11000 samples, validate on 5335 samples\n",
      "Epoch 1/20\n",
      " - 2s - loss: 8.5867 - acc: 0.0911 - val_loss: 2.5006 - val_acc: 0.0909\n",
      "Epoch 2/20\n",
      " - 2s - loss: 7.6096 - acc: 0.0919 - val_loss: 2.4465 - val_acc: 0.0909\n",
      "Epoch 3/20\n",
      " - 2s - loss: 6.5639 - acc: 0.0886 - val_loss: 2.4575 - val_acc: 0.0909\n",
      "Epoch 4/20\n",
      " - 2s - loss: 6.0123 - acc: 0.0903 - val_loss: 2.4990 - val_acc: 0.0909\n",
      "Epoch 5/20\n",
      " - 3s - loss: 5.5840 - acc: 0.0915 - val_loss: 2.4615 - val_acc: 0.0909\n",
      "Epoch 6/20\n",
      " - 3s - loss: 5.4138 - acc: 0.0895 - val_loss: 2.4608 - val_acc: 0.0909\n",
      "Epoch 7/20\n",
      " - 2s - loss: 5.0161 - acc: 0.0912 - val_loss: 2.4361 - val_acc: 0.0909\n",
      "Epoch 8/20\n",
      " - 2s - loss: 4.8379 - acc: 0.0907 - val_loss: 2.4314 - val_acc: 0.0909\n",
      "Epoch 9/20\n",
      " - 2s - loss: 4.7757 - acc: 0.0902 - val_loss: 2.4226 - val_acc: 0.0909\n",
      "Epoch 10/20\n",
      " - 3s - loss: 4.7592 - acc: 0.0873 - val_loss: 2.4234 - val_acc: 0.0909\n",
      "Epoch 11/20\n",
      " - 2s - loss: 4.5655 - acc: 0.0939 - val_loss: 2.4163 - val_acc: 0.0909\n",
      "Epoch 12/20\n",
      " - 3s - loss: 4.5166 - acc: 0.0892 - val_loss: 2.4083 - val_acc: 0.0909\n",
      "Epoch 13/20\n",
      " - 2s - loss: 4.4249 - acc: 0.0923 - val_loss: 2.4069 - val_acc: 0.0909\n",
      "Epoch 14/20\n",
      " - 2s - loss: 4.4780 - acc: 0.0888 - val_loss: 2.4041 - val_acc: 0.0909\n",
      "Epoch 15/20\n",
      " - 2s - loss: 4.3410 - acc: 0.0859 - val_loss: 2.4031 - val_acc: 0.0909\n",
      "Epoch 16/20\n",
      " - 2s - loss: 4.3289 - acc: 0.0904 - val_loss: 2.4008 - val_acc: 0.0909\n",
      "Epoch 17/20\n",
      " - 2s - loss: 4.2525 - acc: 0.0926 - val_loss: 2.4011 - val_acc: 0.0909\n",
      "Epoch 18/20\n",
      " - 3s - loss: 4.2617 - acc: 0.0894 - val_loss: 2.3997 - val_acc: 0.0909\n",
      "Epoch 19/20\n",
      " - 3s - loss: 4.2852 - acc: 0.0925 - val_loss: 2.4015 - val_acc: 0.0909\n",
      "Epoch 20/20\n",
      " - 3s - loss: 4.3758 - acc: 0.0881 - val_loss: 2.3998 - val_acc: 0.0909\n",
      "Test accuracy: 0.09090909090350471\n",
      "Train on 11000 samples, validate on 5335 samples\n",
      "Epoch 1/20\n",
      " - 3s - loss: 14.2277 - acc: 0.0874 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 2/20\n",
      " - 2s - loss: 14.6166 - acc: 0.0918 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 3/20\n",
      " - 3s - loss: 14.6542 - acc: 0.0904 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 4/20\n",
      " - 3s - loss: 14.6324 - acc: 0.0918 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 5/20\n",
      " - 3s - loss: 14.6335 - acc: 0.0913 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 6/20\n",
      " - 3s - loss: 14.6289 - acc: 0.0921 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 7/20\n",
      " - 3s - loss: 14.6559 - acc: 0.0903 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 8/20\n",
      " - 2s - loss: 14.6574 - acc: 0.0902 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 9/20\n",
      " - 2s - loss: 14.6746 - acc: 0.0892 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 10/20\n",
      " - 2s - loss: 14.6495 - acc: 0.0911 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 11/20\n",
      " - 2s - loss: 14.6367 - acc: 0.0916 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 12/20\n",
      " - 2s - loss: 14.6304 - acc: 0.0920 - val_loss: 14.6434 - val_acc: 0.0913\n",
      "Epoch 13/20\n",
      " - 2s - loss: 14.6713 - acc: 0.0894 - val_loss: 14.6528 - val_acc: 0.0909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      " - 2s - loss: 14.5996 - acc: 0.0939 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 15/20\n",
      " - 2s - loss: 14.6175 - acc: 0.0930 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 16/20\n",
      " - 2s - loss: 14.5886 - acc: 0.0947 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 17/20\n",
      " - 2s - loss: 14.6331 - acc: 0.0921 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 18/20\n",
      " - 2s - loss: 14.6074 - acc: 0.0935 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 19/20\n",
      " - 2s - loss: 14.6491 - acc: 0.0909 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 20/20\n",
      " - 2s - loss: 14.6422 - acc: 0.0914 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Test accuracy: 0.09090909089791853\n",
      "Train on 11000 samples, validate on 5335 samples\n",
      "Epoch 1/20\n",
      " - 4s - loss: 14.3815 - acc: 0.0904 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 2/20\n",
      " - 4s - loss: 14.6528 - acc: 0.0909 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 3/20\n",
      " - 3s - loss: 14.6528 - acc: 0.0909 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 4/20\n",
      " - 3s - loss: 14.6528 - acc: 0.0909 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 5/20\n",
      " - 3s - loss: 14.6528 - acc: 0.0909 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 6/20\n",
      " - 3s - loss: 14.6528 - acc: 0.0909 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 7/20\n",
      " - 3s - loss: 14.6528 - acc: 0.0909 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 8/20\n",
      " - 3s - loss: 14.6528 - acc: 0.0909 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 9/20\n",
      " - 3s - loss: 14.6528 - acc: 0.0909 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 10/20\n",
      " - 3s - loss: 14.6528 - acc: 0.0909 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 11/20\n",
      " - 3s - loss: 14.6528 - acc: 0.0909 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 12/20\n",
      " - 3s - loss: 14.6528 - acc: 0.0909 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 13/20\n",
      " - 3s - loss: 14.6528 - acc: 0.0909 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 14/20\n",
      " - 3s - loss: 14.6528 - acc: 0.0909 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 15/20\n",
      " - 3s - loss: 14.6528 - acc: 0.0909 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 16/20\n",
      " - 3s - loss: 14.6528 - acc: 0.0909 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 17/20\n",
      " - 3s - loss: 14.6528 - acc: 0.0909 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 18/20\n",
      " - 3s - loss: 14.6528 - acc: 0.0909 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 19/20\n",
      " - 3s - loss: 14.6528 - acc: 0.0909 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Epoch 20/20\n",
      " - 3s - loss: 14.6528 - acc: 0.0909 - val_loss: 14.6528 - val_acc: 0.0909\n",
      "Test accuracy: 0.09090909090350471\n",
      "Train on 11000 samples, validate on 5335 samples\n",
      "Epoch 1/20\n",
      " - 2s - loss: 8.5384 - acc: 0.1063 - val_loss: 2.5407 - val_acc: 0.0920\n",
      "Epoch 2/20\n",
      " - 1s - loss: 3.6129 - acc: 0.1028 - val_loss: 2.4083 - val_acc: 0.1005\n",
      "Epoch 3/20\n",
      " - 1s - loss: 2.3402 - acc: 0.1209 - val_loss: 2.2520 - val_acc: 0.1417\n",
      "Epoch 4/20\n",
      " - 1s - loss: 2.3032 - acc: 0.1227 - val_loss: 2.2174 - val_acc: 0.1604\n",
      "Epoch 5/20\n",
      " - 2s - loss: 2.2814 - acc: 0.1302 - val_loss: 2.2263 - val_acc: 0.1634\n",
      "Epoch 6/20\n",
      " - 1s - loss: 2.2732 - acc: 0.1375 - val_loss: 2.2073 - val_acc: 0.1646\n",
      "Epoch 7/20\n",
      " - 1s - loss: 2.2658 - acc: 0.1323 - val_loss: 2.1921 - val_acc: 0.1612\n",
      "Epoch 8/20\n",
      " - 1s - loss: 2.2677 - acc: 0.1287 - val_loss: 2.2256 - val_acc: 0.1618\n",
      "Epoch 9/20\n",
      " - 1s - loss: 2.2682 - acc: 0.1327 - val_loss: 2.2118 - val_acc: 0.1691\n",
      "Epoch 10/20\n",
      " - 2s - loss: 2.2621 - acc: 0.1369 - val_loss: 2.2079 - val_acc: 0.1634\n",
      "Epoch 11/20\n",
      " - 2s - loss: 2.2596 - acc: 0.1308 - val_loss: 2.1915 - val_acc: 0.1693\n",
      "Epoch 12/20\n",
      " - 2s - loss: 2.2529 - acc: 0.1373 - val_loss: 2.1973 - val_acc: 0.1683\n",
      "Epoch 13/20\n",
      " - 1s - loss: 2.2462 - acc: 0.1373 - val_loss: 2.1955 - val_acc: 0.1698\n",
      "Epoch 14/20\n",
      " - 1s - loss: 2.2391 - acc: 0.1424 - val_loss: 2.1229 - val_acc: 0.1929\n",
      "Epoch 15/20\n",
      " - 1s - loss: 2.2218 - acc: 0.1435 - val_loss: 2.1347 - val_acc: 0.2036\n",
      "Epoch 16/20\n",
      " - 1s - loss: 2.2078 - acc: 0.1573 - val_loss: 2.1356 - val_acc: 0.2178\n",
      "Epoch 17/20\n",
      " - 1s - loss: 2.1989 - acc: 0.1556 - val_loss: 2.0983 - val_acc: 0.2217\n",
      "Epoch 18/20\n",
      " - 1s - loss: 2.1662 - acc: 0.1712 - val_loss: 2.0587 - val_acc: 0.2347\n",
      "Epoch 19/20\n",
      " - 1s - loss: 2.1017 - acc: 0.2046 - val_loss: 2.0418 - val_acc: 0.2478\n",
      "Epoch 20/20\n",
      " - 1s - loss: 2.0406 - acc: 0.2061 - val_loss: 1.9486 - val_acc: 0.3335\n",
      "Test accuracy: 0.33345829422158846\n",
      "Train on 11000 samples, validate on 5335 samples\n",
      "Epoch 1/20\n",
      " - 4s - loss: 6.8873 - acc: 0.0944 - val_loss: 2.5679 - val_acc: 0.0840\n",
      "Epoch 2/20\n",
      " - 3s - loss: 3.9499 - acc: 0.0907 - val_loss: 2.8349 - val_acc: 0.0903\n",
      "Epoch 3/20\n",
      " - 3s - loss: 3.2849 - acc: 0.0880 - val_loss: 3.2217 - val_acc: 0.0909\n",
      "Epoch 4/20\n",
      " - 3s - loss: 2.9430 - acc: 0.0862 - val_loss: 2.5656 - val_acc: 0.0902\n",
      "Epoch 5/20\n",
      " - 3s - loss: 2.9006 - acc: 0.0922 - val_loss: 2.6077 - val_acc: 0.0905\n",
      "Epoch 6/20\n",
      " - 3s - loss: 2.8219 - acc: 0.0875 - val_loss: 2.4859 - val_acc: 0.0924\n",
      "Epoch 7/20\n",
      " - 3s - loss: 2.7184 - acc: 0.0944 - val_loss: 2.4975 - val_acc: 0.0935\n",
      "Epoch 8/20\n",
      " - 3s - loss: 2.7287 - acc: 0.0891 - val_loss: 2.4639 - val_acc: 0.1007\n",
      "Epoch 9/20\n",
      " - 3s - loss: 2.6975 - acc: 0.0905 - val_loss: 2.4864 - val_acc: 0.0913\n",
      "Epoch 10/20\n",
      " - 3s - loss: 2.7075 - acc: 0.0912 - val_loss: 2.4472 - val_acc: 0.1102\n",
      "Epoch 11/20\n",
      " - 3s - loss: 2.7200 - acc: 0.0917 - val_loss: 2.3811 - val_acc: 0.1415\n",
      "Epoch 12/20\n",
      " - 3s - loss: 2.7012 - acc: 0.0915 - val_loss: 2.3799 - val_acc: 0.1085\n",
      "Epoch 13/20\n",
      " - 3s - loss: 2.7236 - acc: 0.0898 - val_loss: 2.3667 - val_acc: 0.1406\n",
      "Epoch 14/20\n",
      " - 3s - loss: 2.6997 - acc: 0.0921 - val_loss: 2.3591 - val_acc: 0.1177\n",
      "Epoch 15/20\n",
      " - 3s - loss: 2.5983 - acc: 0.0865 - val_loss: 2.3548 - val_acc: 0.1065\n",
      "Epoch 16/20\n",
      " - 3s - loss: 2.5490 - acc: 0.0909 - val_loss: 2.3519 - val_acc: 0.0995\n",
      "Epoch 17/20\n",
      " - 3s - loss: 2.5729 - acc: 0.0921 - val_loss: 2.3709 - val_acc: 0.1239\n",
      "Epoch 18/20\n",
      " - 3s - loss: 2.5309 - acc: 0.0884 - val_loss: 2.3672 - val_acc: 0.1265\n",
      "Epoch 19/20\n",
      " - 3s - loss: 2.5671 - acc: 0.0885 - val_loss: 2.3474 - val_acc: 0.1477\n",
      "Epoch 20/20\n",
      " - 3s - loss: 2.5799 - acc: 0.0964 - val_loss: 2.3698 - val_acc: 0.1273\n",
      "Test accuracy: 0.12727272727971\n",
      "Train on 11000 samples, validate on 5335 samples\n",
      "Epoch 1/20\n",
      " - 1s - loss: 3.3981 - acc: 0.0878 - val_loss: 2.5117 - val_acc: 0.0909\n",
      "Epoch 2/20\n",
      " - 1s - loss: 3.3566 - acc: 0.0935 - val_loss: 2.4750 - val_acc: 0.0909\n",
      "Epoch 3/20\n",
      " - 1s - loss: 3.2983 - acc: 0.0945 - val_loss: 2.4498 - val_acc: 0.0909\n",
      "Epoch 4/20\n",
      " - 1s - loss: 3.2925 - acc: 0.0915 - val_loss: 2.4321 - val_acc: 0.0909\n",
      "Epoch 5/20\n",
      " - 1s - loss: 3.2869 - acc: 0.0932 - val_loss: 2.4201 - val_acc: 0.0909\n",
      "Epoch 6/20\n",
      " - 1s - loss: 3.2766 - acc: 0.0932 - val_loss: 2.4126 - val_acc: 0.0909\n",
      "Epoch 7/20\n",
      " - 1s - loss: 3.2510 - acc: 0.0919 - val_loss: 2.4079 - val_acc: 0.0909\n",
      "Epoch 8/20\n",
      " - 1s - loss: 3.2563 - acc: 0.0919 - val_loss: 2.4047 - val_acc: 0.0909\n",
      "Epoch 9/20\n",
      " - 1s - loss: 3.2645 - acc: 0.0912 - val_loss: 2.4024 - val_acc: 0.0909\n",
      "Epoch 10/20\n",
      " - 1s - loss: 3.2412 - acc: 0.0866 - val_loss: 2.4009 - val_acc: 0.0909\n",
      "Epoch 11/20\n",
      " - 1s - loss: 3.2522 - acc: 0.0873 - val_loss: 2.3999 - val_acc: 0.0909\n",
      "Epoch 12/20\n",
      " - 1s - loss: 3.2441 - acc: 0.0901 - val_loss: 2.3992 - val_acc: 0.0909\n",
      "Epoch 13/20\n",
      " - 1s - loss: 3.2346 - acc: 0.0874 - val_loss: 2.3987 - val_acc: 0.0915\n",
      "Epoch 14/20\n",
      " - 1s - loss: 3.2315 - acc: 0.0832 - val_loss: 2.3984 - val_acc: 0.0922\n",
      "Epoch 15/20\n",
      " - 1s - loss: 3.2214 - acc: 0.0905 - val_loss: 2.3982 - val_acc: 0.0930\n",
      "Epoch 16/20\n",
      " - 1s - loss: 3.2323 - acc: 0.0928 - val_loss: 2.3981 - val_acc: 0.0917\n",
      "Epoch 17/20\n",
      " - 1s - loss: 3.2075 - acc: 0.0959 - val_loss: 2.3980 - val_acc: 0.0932\n",
      "Epoch 18/20\n",
      " - 1s - loss: 3.2263 - acc: 0.0921 - val_loss: 2.3979 - val_acc: 0.0939\n",
      "Epoch 19/20\n",
      " - 1s - loss: 3.1858 - acc: 0.0920 - val_loss: 2.3978 - val_acc: 0.0917\n",
      "Epoch 20/20\n",
      " - 1s - loss: 3.1967 - acc: 0.0940 - val_loss: 2.3977 - val_acc: 0.0918\n",
      "Test accuracy: 0.09184629803186505\n",
      "Train on 11000 samples, validate on 5335 samples\n",
      "Epoch 1/20\n",
      " - 1s - loss: 2.3055 - acc: 0.1852 - val_loss: 1.7407 - val_acc: 0.4665\n",
      "Epoch 2/20\n",
      " - 1s - loss: 1.9134 - acc: 0.3126 - val_loss: 1.4203 - val_acc: 0.5509\n",
      "Epoch 3/20\n",
      " - 1s - loss: 1.7164 - acc: 0.3717 - val_loss: 1.2576 - val_acc: 0.6232\n",
      "Epoch 4/20\n",
      " - 1s - loss: 1.6148 - acc: 0.4143 - val_loss: 1.1489 - val_acc: 0.6540\n",
      "Epoch 5/20\n",
      " - 1s - loss: 1.5462 - acc: 0.4347 - val_loss: 1.1159 - val_acc: 0.6767\n",
      "Epoch 6/20\n",
      " - 1s - loss: 1.4750 - acc: 0.4666 - val_loss: 1.0601 - val_acc: 0.6860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      " - 1s - loss: 1.4165 - acc: 0.4916 - val_loss: 1.0478 - val_acc: 0.6858\n",
      "Epoch 8/20\n",
      " - 1s - loss: 1.3767 - acc: 0.5011 - val_loss: 1.0168 - val_acc: 0.6945\n",
      "Epoch 9/20\n",
      " - 1s - loss: 1.3353 - acc: 0.5183 - val_loss: 1.0012 - val_acc: 0.7040\n",
      "Epoch 10/20\n",
      " - 1s - loss: 1.3193 - acc: 0.5198 - val_loss: 1.0011 - val_acc: 0.6945\n",
      "Epoch 11/20\n",
      " - 1s - loss: 1.2739 - acc: 0.5368 - val_loss: 0.9809 - val_acc: 0.7112\n",
      "Epoch 12/20\n",
      " - 1s - loss: 1.2583 - acc: 0.5515 - val_loss: 0.9576 - val_acc: 0.7063\n",
      "Epoch 13/20\n",
      " - 1s - loss: 1.2370 - acc: 0.5584 - val_loss: 0.9434 - val_acc: 0.7042\n",
      "Epoch 14/20\n",
      " - 1s - loss: 1.2363 - acc: 0.5664 - val_loss: 0.9436 - val_acc: 0.7179\n",
      "Epoch 15/20\n",
      " - 1s - loss: 1.2050 - acc: 0.5706 - val_loss: 0.9264 - val_acc: 0.7203\n",
      "Epoch 16/20\n",
      " - 1s - loss: 1.1785 - acc: 0.5779 - val_loss: 0.9265 - val_acc: 0.7166\n",
      "Epoch 17/20\n",
      " - 1s - loss: 1.1965 - acc: 0.5824 - val_loss: 0.9173 - val_acc: 0.7226\n",
      "Epoch 18/20\n",
      " - 1s - loss: 1.1817 - acc: 0.5812 - val_loss: 0.9125 - val_acc: 0.7248\n",
      "Epoch 19/20\n",
      " - 1s - loss: 1.1689 - acc: 0.5875 - val_loss: 0.9083 - val_acc: 0.7280\n",
      "Epoch 20/20\n",
      " - 1s - loss: 1.1365 - acc: 0.6031 - val_loss: 0.8901 - val_acc: 0.7282\n",
      "Test accuracy: 0.7282099344513633\n",
      "Train on 11000 samples, validate on 5335 samples\n",
      "Epoch 1/20\n",
      " - 1s - loss: 2.3982 - acc: 0.0896 - val_loss: 2.3978 - val_acc: 0.0937\n",
      "Epoch 2/20\n",
      " - 0s - loss: 2.3980 - acc: 0.0912 - val_loss: 2.3977 - val_acc: 0.0988\n",
      "Epoch 3/20\n",
      " - 0s - loss: 2.3978 - acc: 0.0915 - val_loss: 2.3975 - val_acc: 0.1023\n",
      "Epoch 4/20\n",
      " - 0s - loss: 2.3977 - acc: 0.0964 - val_loss: 2.3974 - val_acc: 0.1061\n",
      "Epoch 5/20\n",
      " - 0s - loss: 2.3976 - acc: 0.0975 - val_loss: 2.3973 - val_acc: 0.1138\n",
      "Epoch 6/20\n",
      " - 0s - loss: 2.3974 - acc: 0.0976 - val_loss: 2.3972 - val_acc: 0.1228\n",
      "Epoch 7/20\n",
      " - 0s - loss: 2.3974 - acc: 0.0980 - val_loss: 2.3971 - val_acc: 0.1316\n",
      "Epoch 8/20\n",
      " - 0s - loss: 2.3973 - acc: 0.0989 - val_loss: 2.3970 - val_acc: 0.1344\n",
      "Epoch 9/20\n",
      " - 0s - loss: 2.3973 - acc: 0.1023 - val_loss: 2.3969 - val_acc: 0.1455\n",
      "Epoch 10/20\n",
      " - 0s - loss: 2.3971 - acc: 0.1050 - val_loss: 2.3968 - val_acc: 0.1481\n",
      "Epoch 11/20\n",
      " - 0s - loss: 2.3971 - acc: 0.0965 - val_loss: 2.3967 - val_acc: 0.1524\n",
      "Epoch 12/20\n",
      " - 0s - loss: 2.3969 - acc: 0.1080 - val_loss: 2.3966 - val_acc: 0.1552\n",
      "Epoch 13/20\n",
      " - 0s - loss: 2.3969 - acc: 0.1045 - val_loss: 2.3965 - val_acc: 0.1552\n",
      "Epoch 14/20\n",
      " - 0s - loss: 2.3969 - acc: 0.1033 - val_loss: 2.3964 - val_acc: 0.1590\n",
      "Epoch 15/20\n",
      " - 0s - loss: 2.3970 - acc: 0.1002 - val_loss: 2.3964 - val_acc: 0.1584\n",
      "Epoch 16/20\n",
      " - 0s - loss: 2.3967 - acc: 0.1065 - val_loss: 2.3963 - val_acc: 0.1571\n",
      "Epoch 17/20\n",
      " - 0s - loss: 2.3966 - acc: 0.1085 - val_loss: 2.3962 - val_acc: 0.1612\n",
      "Epoch 18/20\n",
      " - 0s - loss: 2.3966 - acc: 0.1068 - val_loss: 2.3962 - val_acc: 0.1634\n",
      "Epoch 19/20\n",
      " - 0s - loss: 2.3965 - acc: 0.1116 - val_loss: 2.3961 - val_acc: 0.1601\n",
      "Epoch 20/20\n",
      " - 0s - loss: 2.3968 - acc: 0.1002 - val_loss: 2.3961 - val_acc: 0.1595\n",
      "Test accuracy: 0.15951265229057127\n",
      "Train on 11000 samples, validate on 5335 samples\n",
      "Epoch 1/20\n",
      " - 2s - loss: 2.3980 - acc: 0.0860 - val_loss: 2.3979 - val_acc: 0.0787\n",
      "Epoch 2/20\n",
      " - 1s - loss: 2.3978 - acc: 0.0970 - val_loss: 2.3978 - val_acc: 0.0890\n",
      "Epoch 3/20\n",
      " - 1s - loss: 2.3978 - acc: 0.0941 - val_loss: 2.3977 - val_acc: 0.1007\n",
      "Epoch 4/20\n",
      " - 1s - loss: 2.3977 - acc: 0.1028 - val_loss: 2.3976 - val_acc: 0.1123\n",
      "Epoch 5/20\n",
      " - 1s - loss: 2.3976 - acc: 0.1079 - val_loss: 2.3976 - val_acc: 0.1215\n",
      "Epoch 6/20\n",
      " - 1s - loss: 2.3976 - acc: 0.1088 - val_loss: 2.3975 - val_acc: 0.1295\n",
      "Epoch 7/20\n",
      " - 1s - loss: 2.3975 - acc: 0.1128 - val_loss: 2.3975 - val_acc: 0.1391\n",
      "Epoch 8/20\n",
      " - 1s - loss: 2.3975 - acc: 0.1120 - val_loss: 2.3974 - val_acc: 0.1455\n",
      "Epoch 9/20\n",
      " - 1s - loss: 2.3975 - acc: 0.1125 - val_loss: 2.3974 - val_acc: 0.1462\n",
      "Epoch 10/20\n",
      " - 1s - loss: 2.3974 - acc: 0.1173 - val_loss: 2.3974 - val_acc: 0.1398\n",
      "Epoch 11/20\n",
      " - 1s - loss: 2.3974 - acc: 0.1206 - val_loss: 2.3974 - val_acc: 0.1468\n",
      "Epoch 12/20\n",
      " - 1s - loss: 2.3974 - acc: 0.1170 - val_loss: 2.3973 - val_acc: 0.1468\n",
      "Epoch 13/20\n",
      " - 1s - loss: 2.3974 - acc: 0.1174 - val_loss: 2.3973 - val_acc: 0.1503\n",
      "Epoch 14/20\n",
      " - 1s - loss: 2.3974 - acc: 0.1183 - val_loss: 2.3973 - val_acc: 0.1593\n",
      "Epoch 15/20\n",
      " - 1s - loss: 2.3973 - acc: 0.1210 - val_loss: 2.3973 - val_acc: 0.1432\n",
      "Epoch 16/20\n",
      " - 1s - loss: 2.3974 - acc: 0.1168 - val_loss: 2.3973 - val_acc: 0.1537\n",
      "Epoch 17/20\n",
      " - 1s - loss: 2.3973 - acc: 0.1193 - val_loss: 2.3973 - val_acc: 0.1485\n",
      "Epoch 18/20\n",
      " - 1s - loss: 2.3974 - acc: 0.1134 - val_loss: 2.3972 - val_acc: 0.1603\n",
      "Epoch 19/20\n",
      " - 1s - loss: 2.3973 - acc: 0.1163 - val_loss: 2.3972 - val_acc: 0.1603\n",
      "Epoch 20/20\n",
      " - 2s - loss: 2.3973 - acc: 0.1227 - val_loss: 2.3972 - val_acc: 0.1689\n",
      "Test accuracy: 0.1688847235183126\n",
      "Train on 11000 samples, validate on 5335 samples\n",
      "Epoch 1/20\n",
      " - 4s - loss: 2.5599 - acc: 0.0967 - val_loss: 2.3996 - val_acc: 0.0909\n",
      "Epoch 2/20\n",
      " - 3s - loss: 2.5664 - acc: 0.0890 - val_loss: 2.4014 - val_acc: 0.0909\n",
      "Epoch 3/20\n",
      " - 3s - loss: 2.5615 - acc: 0.0934 - val_loss: 2.3993 - val_acc: 0.0909\n",
      "Epoch 4/20\n",
      " - 3s - loss: 2.5583 - acc: 0.0913 - val_loss: 2.3997 - val_acc: 0.0909\n",
      "Epoch 5/20\n",
      " - 3s - loss: 2.5579 - acc: 0.0915 - val_loss: 2.4017 - val_acc: 0.0909\n",
      "Epoch 6/20\n",
      " - 3s - loss: 2.5468 - acc: 0.0963 - val_loss: 2.4018 - val_acc: 0.0909\n",
      "Epoch 7/20\n",
      " - 3s - loss: 2.5552 - acc: 0.0922 - val_loss: 2.3994 - val_acc: 0.0909\n",
      "Epoch 8/20\n",
      " - 3s - loss: 2.5487 - acc: 0.0928 - val_loss: 2.4005 - val_acc: 0.0909\n",
      "Epoch 9/20\n",
      " - 3s - loss: 2.5508 - acc: 0.0912 - val_loss: 2.4010 - val_acc: 0.0909\n",
      "Epoch 10/20\n",
      " - 3s - loss: 2.5457 - acc: 0.0885 - val_loss: 2.3991 - val_acc: 0.0911\n",
      "Epoch 11/20\n",
      " - 3s - loss: 2.5412 - acc: 0.0925 - val_loss: 2.3998 - val_acc: 0.0909\n",
      "Epoch 12/20\n",
      " - 3s - loss: 2.5423 - acc: 0.0894 - val_loss: 2.3999 - val_acc: 0.0909\n",
      "Epoch 13/20\n",
      " - 3s - loss: 2.5426 - acc: 0.0864 - val_loss: 2.4015 - val_acc: 0.0909\n",
      "Epoch 14/20\n",
      " - 3s - loss: 2.5357 - acc: 0.0925 - val_loss: 2.3995 - val_acc: 0.0909\n",
      "Epoch 15/20\n",
      " - 3s - loss: 2.5398 - acc: 0.0890 - val_loss: 2.3992 - val_acc: 0.0909\n",
      "Epoch 16/20\n",
      " - 3s - loss: 2.5293 - acc: 0.0950 - val_loss: 2.4024 - val_acc: 0.0909\n",
      "Epoch 17/20\n",
      " - 3s - loss: 2.5228 - acc: 0.0942 - val_loss: 2.3998 - val_acc: 0.0909\n",
      "Epoch 18/20\n",
      " - 3s - loss: 2.5257 - acc: 0.0938 - val_loss: 2.4011 - val_acc: 0.0909\n",
      "Epoch 19/20\n",
      " - 3s - loss: 2.5282 - acc: 0.0929 - val_loss: 2.3990 - val_acc: 0.0909\n",
      "Epoch 20/20\n",
      " - 3s - loss: 2.5259 - acc: 0.0898 - val_loss: 2.4005 - val_acc: 0.0909\n",
      "Test accuracy: 0.09090909090909091\n",
      "Train on 11000 samples, validate on 5335 samples\n",
      "Epoch 1/20\n",
      " - 5s - loss: 2.5818 - acc: 0.1350 - val_loss: 2.0586 - val_acc: 0.2512\n",
      "Epoch 2/20\n",
      " - 4s - loss: 2.0761 - acc: 0.1839 - val_loss: 1.9391 - val_acc: 0.2193\n",
      "Epoch 3/20\n",
      " - 4s - loss: 2.0227 - acc: 0.1996 - val_loss: 1.9052 - val_acc: 0.1921\n",
      "Epoch 4/20\n",
      " - 4s - loss: 1.9455 - acc: 0.2168 - val_loss: 1.8369 - val_acc: 0.3145\n",
      "Epoch 5/20\n",
      " - 4s - loss: 1.9172 - acc: 0.2271 - val_loss: 1.7996 - val_acc: 0.3366\n",
      "Epoch 6/20\n",
      " - 4s - loss: 1.8688 - acc: 0.2461 - val_loss: 1.7362 - val_acc: 0.3400\n",
      "Epoch 7/20\n",
      " - 4s - loss: 1.8732 - acc: 0.2498 - val_loss: 1.8046 - val_acc: 0.2396\n",
      "Epoch 8/20\n",
      " - 4s - loss: 1.8490 - acc: 0.2591 - val_loss: 1.7092 - val_acc: 0.2579\n",
      "Epoch 9/20\n",
      " - 4s - loss: 1.8110 - acc: 0.2743 - val_loss: 1.7368 - val_acc: 0.3205\n",
      "Epoch 10/20\n",
      " - 4s - loss: 1.7933 - acc: 0.2800 - val_loss: 1.8584 - val_acc: 0.2394\n",
      "Epoch 11/20\n",
      " - 4s - loss: 1.7817 - acc: 0.2859 - val_loss: 1.7315 - val_acc: 0.2545\n",
      "Epoch 12/20\n",
      " - 5s - loss: 1.7788 - acc: 0.2795 - val_loss: 1.7866 - val_acc: 0.2853\n",
      "Epoch 13/20\n",
      " - 5s - loss: 1.7548 - acc: 0.2949 - val_loss: 1.7462 - val_acc: 0.3087\n",
      "Epoch 14/20\n",
      " - 4s - loss: 1.7602 - acc: 0.2915 - val_loss: 1.7203 - val_acc: 0.3185\n",
      "Epoch 15/20\n",
      " - 4s - loss: 1.7177 - acc: 0.3073 - val_loss: 1.7006 - val_acc: 0.3010\n",
      "Epoch 16/20\n",
      " - 4s - loss: 1.7202 - acc: 0.3100 - val_loss: 1.6368 - val_acc: 0.3946\n",
      "Epoch 17/20\n",
      " - 4s - loss: 1.6786 - acc: 0.3215 - val_loss: 1.6061 - val_acc: 0.3818\n",
      "Epoch 18/20\n",
      " - 4s - loss: 1.6707 - acc: 0.3313 - val_loss: 1.5851 - val_acc: 0.4212\n",
      "Epoch 19/20\n",
      " - 4s - loss: 1.6535 - acc: 0.3373 - val_loss: 1.7123 - val_acc: 0.3456\n",
      "Epoch 20/20\n",
      " - 4s - loss: 1.6650 - acc: 0.3340 - val_loss: 1.6183 - val_acc: 0.4191\n",
      "Test accuracy: 0.4191190252431442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11000 samples, validate on 5335 samples\n",
      "Epoch 1/20\n",
      " - 2s - loss: 2.5766 - acc: 0.0875 - val_loss: 2.4030 - val_acc: 0.0909\n",
      "Epoch 2/20\n",
      " - 1s - loss: 2.4983 - acc: 0.0900 - val_loss: 2.4002 - val_acc: 0.0909\n",
      "Epoch 3/20\n",
      " - 1s - loss: 2.4573 - acc: 0.0902 - val_loss: 2.3989 - val_acc: 0.0909\n",
      "Epoch 4/20\n",
      " - 1s - loss: 2.4426 - acc: 0.0844 - val_loss: 2.3982 - val_acc: 0.0909\n",
      "Epoch 5/20\n",
      " - 1s - loss: 2.4265 - acc: 0.0885 - val_loss: 2.3983 - val_acc: 0.0909\n",
      "Epoch 6/20\n",
      " - 1s - loss: 2.4198 - acc: 0.0866 - val_loss: 2.3982 - val_acc: 0.0909\n",
      "Epoch 7/20\n",
      " - 1s - loss: 2.4153 - acc: 0.0913 - val_loss: 2.3981 - val_acc: 0.0909\n",
      "Epoch 8/20\n",
      " - 1s - loss: 2.4104 - acc: 0.0940 - val_loss: 2.3980 - val_acc: 0.0909\n",
      "Epoch 9/20\n",
      " - 2s - loss: 2.4086 - acc: 0.0888 - val_loss: 2.3980 - val_acc: 0.0909\n",
      "Epoch 10/20\n",
      " - 1s - loss: 2.4080 - acc: 0.0945 - val_loss: 2.3980 - val_acc: 0.0909\n",
      "Epoch 11/20\n",
      " - 1s - loss: 2.4063 - acc: 0.0912 - val_loss: 2.3979 - val_acc: 0.0909\n",
      "Epoch 12/20\n",
      " - 1s - loss: 2.4017 - acc: 0.0935 - val_loss: 2.3979 - val_acc: 0.0915\n",
      "Epoch 13/20\n",
      " - 1s - loss: 2.4042 - acc: 0.0913 - val_loss: 2.3979 - val_acc: 0.0909\n",
      "Epoch 14/20\n",
      " - 1s - loss: 2.4031 - acc: 0.0904 - val_loss: 2.3979 - val_acc: 0.0909\n",
      "Epoch 15/20\n",
      " - 1s - loss: 2.4038 - acc: 0.0883 - val_loss: 2.3979 - val_acc: 0.0909\n",
      "Epoch 16/20\n",
      " - 1s - loss: 2.4021 - acc: 0.0887 - val_loss: 2.3979 - val_acc: 0.0909\n",
      "Epoch 17/20\n",
      " - 1s - loss: 2.4026 - acc: 0.0907 - val_loss: 2.3979 - val_acc: 0.0909\n",
      "Epoch 18/20\n",
      " - 1s - loss: 2.4025 - acc: 0.0905 - val_loss: 2.3979 - val_acc: 0.0909\n",
      "Epoch 19/20\n",
      " - 1s - loss: 2.4031 - acc: 0.0915 - val_loss: 2.3979 - val_acc: 0.0909\n",
      "Epoch 20/20\n",
      " - 1s - loss: 2.4016 - acc: 0.0889 - val_loss: 2.3979 - val_acc: 0.0909\n",
      "Test accuracy: 0.09090909090909091\n",
      "Train on 11000 samples, validate on 5335 samples\n",
      "Epoch 1/20\n",
      " - 6s - loss: 1.7228 - acc: 0.3777 - val_loss: 1.0233 - val_acc: 0.6499\n",
      "Epoch 2/20\n",
      " - 5s - loss: 1.1387 - acc: 0.6016 - val_loss: 0.8431 - val_acc: 0.7280\n",
      "Epoch 3/20\n",
      " - 5s - loss: 0.9405 - acc: 0.6715 - val_loss: 0.7319 - val_acc: 0.7582\n",
      "Epoch 4/20\n",
      " - 5s - loss: 0.7849 - acc: 0.7275 - val_loss: 0.6615 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      " - 5s - loss: 0.6683 - acc: 0.7685 - val_loss: 0.6354 - val_acc: 0.7985\n",
      "Epoch 6/20\n",
      " - 5s - loss: 0.5899 - acc: 0.7981 - val_loss: 0.6167 - val_acc: 0.8011\n",
      "Epoch 7/20\n",
      " - 5s - loss: 0.5003 - acc: 0.8280 - val_loss: 0.5951 - val_acc: 0.8052\n",
      "Epoch 8/20\n",
      " - 5s - loss: 0.4342 - acc: 0.8487 - val_loss: 0.5863 - val_acc: 0.8193\n",
      "Epoch 9/20\n",
      " - 5s - loss: 0.3770 - acc: 0.8709 - val_loss: 0.5834 - val_acc: 0.8182\n",
      "Epoch 10/20\n",
      " - 5s - loss: 0.3284 - acc: 0.8854 - val_loss: 0.5973 - val_acc: 0.8204\n",
      "Epoch 11/20\n",
      " - 5s - loss: 0.3005 - acc: 0.8978 - val_loss: 0.6124 - val_acc: 0.8221\n",
      "Epoch 12/20\n",
      " - 5s - loss: 0.2801 - acc: 0.9034 - val_loss: 0.6227 - val_acc: 0.8202\n",
      "Epoch 13/20\n",
      " - 5s - loss: 0.2486 - acc: 0.9138 - val_loss: 0.6067 - val_acc: 0.8289\n",
      "Epoch 14/20\n",
      " - 5s - loss: 0.2171 - acc: 0.9261 - val_loss: 0.6293 - val_acc: 0.8306\n",
      "Epoch 15/20\n",
      " - 5s - loss: 0.2133 - acc: 0.9274 - val_loss: 0.6446 - val_acc: 0.8277\n",
      "Epoch 16/20\n",
      " - 5s - loss: 0.2044 - acc: 0.9293 - val_loss: 0.6621 - val_acc: 0.8223\n",
      "Epoch 17/20\n",
      " - 5s - loss: 0.1834 - acc: 0.9385 - val_loss: 0.6522 - val_acc: 0.8285\n",
      "Epoch 18/20\n",
      " - 5s - loss: 0.1631 - acc: 0.9433 - val_loss: 0.6321 - val_acc: 0.8358\n",
      "Epoch 19/20\n",
      " - 5s - loss: 0.1667 - acc: 0.9459 - val_loss: 0.6683 - val_acc: 0.8246\n",
      "Epoch 20/20\n",
      " - 5s - loss: 0.1528 - acc: 0.9482 - val_loss: 0.6925 - val_acc: 0.8262\n",
      "Test accuracy: 0.8262417993594691\n",
      "Train on 11000 samples, validate on 5335 samples\n",
      "Epoch 1/20\n",
      " - 2s - loss: 2.4573 - acc: 0.0938 - val_loss: 2.3794 - val_acc: 0.1316\n",
      "Epoch 2/20\n",
      " - 1s - loss: 2.4213 - acc: 0.1008 - val_loss: 2.3611 - val_acc: 0.2032\n",
      "Epoch 3/20\n",
      " - 1s - loss: 2.4056 - acc: 0.1086 - val_loss: 2.3437 - val_acc: 0.2671\n",
      "Epoch 4/20\n",
      " - 1s - loss: 2.3812 - acc: 0.1217 - val_loss: 2.3210 - val_acc: 0.3100\n",
      "Epoch 5/20\n",
      " - 1s - loss: 2.3642 - acc: 0.1269 - val_loss: 2.2925 - val_acc: 0.3363\n",
      "Epoch 6/20\n",
      " - 1s - loss: 2.3332 - acc: 0.1444 - val_loss: 2.2515 - val_acc: 0.3590\n",
      "Epoch 7/20\n",
      " - 1s - loss: 2.2993 - acc: 0.1563 - val_loss: 2.1958 - val_acc: 0.3829\n",
      "Epoch 8/20\n",
      " - 1s - loss: 2.2593 - acc: 0.1759 - val_loss: 2.1201 - val_acc: 0.4047\n",
      "Epoch 9/20\n",
      " - 1s - loss: 2.2123 - acc: 0.1929 - val_loss: 2.0352 - val_acc: 0.4165\n",
      "Epoch 10/20\n",
      " - 1s - loss: 2.1551 - acc: 0.2097 - val_loss: 1.9419 - val_acc: 0.4236\n",
      "Epoch 11/20\n",
      " - 1s - loss: 2.0987 - acc: 0.2228 - val_loss: 1.8499 - val_acc: 0.4375\n",
      "Epoch 12/20\n",
      " - 1s - loss: 2.0551 - acc: 0.2273 - val_loss: 1.7774 - val_acc: 0.4424\n",
      "Epoch 13/20\n",
      " - 1s - loss: 2.0083 - acc: 0.2447 - val_loss: 1.7201 - val_acc: 0.4367\n",
      "Epoch 14/20\n",
      " - 1s - loss: 1.9583 - acc: 0.2580 - val_loss: 1.6683 - val_acc: 0.4457\n",
      "Epoch 15/20\n",
      " - 1s - loss: 1.9236 - acc: 0.2685 - val_loss: 1.6293 - val_acc: 0.4557\n",
      "Epoch 16/20\n",
      " - 1s - loss: 1.8939 - acc: 0.2733 - val_loss: 1.6020 - val_acc: 0.4650\n",
      "Epoch 17/20\n",
      " - 1s - loss: 1.8712 - acc: 0.2840 - val_loss: 1.5780 - val_acc: 0.4727\n",
      "Epoch 18/20\n",
      " - 1s - loss: 1.8483 - acc: 0.2894 - val_loss: 1.5565 - val_acc: 0.4553\n",
      "Epoch 19/20\n",
      " - 1s - loss: 1.8235 - acc: 0.2998 - val_loss: 1.5338 - val_acc: 0.4823\n",
      "Epoch 20/20\n",
      " - 1s - loss: 1.7990 - acc: 0.2992 - val_loss: 1.5116 - val_acc: 0.4881\n",
      "Test accuracy: 0.4880974695631133\n",
      "Train on 11000 samples, validate on 5335 samples\n",
      "Epoch 1/20\n",
      " - 1s - loss: 2.7981 - acc: 0.0942 - val_loss: 2.5771 - val_acc: 0.0896\n",
      "Epoch 2/20\n",
      " - 1s - loss: 2.6983 - acc: 0.0930 - val_loss: 2.4987 - val_acc: 0.0924\n",
      "Epoch 3/20\n",
      " - 1s - loss: 2.6300 - acc: 0.0952 - val_loss: 2.4511 - val_acc: 0.1012\n",
      "Epoch 4/20\n",
      " - 1s - loss: 2.5868 - acc: 0.0943 - val_loss: 2.4207 - val_acc: 0.1138\n",
      "Epoch 5/20\n",
      " - 1s - loss: 2.5635 - acc: 0.1007 - val_loss: 2.4002 - val_acc: 0.1278\n",
      "Epoch 6/20\n",
      " - 1s - loss: 2.5539 - acc: 0.0958 - val_loss: 2.3858 - val_acc: 0.1425\n",
      "Epoch 7/20\n",
      " - 1s - loss: 2.5426 - acc: 0.0952 - val_loss: 2.3753 - val_acc: 0.1528\n",
      "Epoch 8/20\n",
      " - 1s - loss: 2.5401 - acc: 0.0956 - val_loss: 2.3674 - val_acc: 0.1672\n",
      "Epoch 9/20\n",
      " - 1s - loss: 2.5216 - acc: 0.1003 - val_loss: 2.3610 - val_acc: 0.1783\n",
      "Epoch 10/20\n",
      " - 1s - loss: 2.5075 - acc: 0.1071 - val_loss: 2.3556 - val_acc: 0.1886\n",
      "Epoch 11/20\n",
      " - 1s - loss: 2.5017 - acc: 0.1039 - val_loss: 2.3509 - val_acc: 0.2030\n",
      "Epoch 12/20\n",
      " - 1s - loss: 2.5081 - acc: 0.1029 - val_loss: 2.3465 - val_acc: 0.2120\n",
      "Epoch 13/20\n",
      " - 1s - loss: 2.4970 - acc: 0.1081 - val_loss: 2.3423 - val_acc: 0.2189\n",
      "Epoch 14/20\n",
      " - 1s - loss: 2.4904 - acc: 0.1083 - val_loss: 2.3383 - val_acc: 0.2276\n",
      "Epoch 15/20\n",
      " - 1s - loss: 2.4971 - acc: 0.1043 - val_loss: 2.3343 - val_acc: 0.2321\n",
      "Epoch 16/20\n",
      " - 1s - loss: 2.4819 - acc: 0.1101 - val_loss: 2.3304 - val_acc: 0.2399\n",
      "Epoch 17/20\n",
      " - 1s - loss: 2.4792 - acc: 0.1154 - val_loss: 2.3265 - val_acc: 0.2442\n",
      "Epoch 18/20\n",
      " - 1s - loss: 2.4746 - acc: 0.1150 - val_loss: 2.3226 - val_acc: 0.2508\n",
      "Epoch 19/20\n",
      " - 1s - loss: 2.4762 - acc: 0.1144 - val_loss: 2.3187 - val_acc: 0.2570\n",
      "Epoch 20/20\n",
      " - 1s - loss: 2.4631 - acc: 0.1175 - val_loss: 2.3147 - val_acc: 0.2624\n",
      "Test accuracy: 0.2624179943711711\n",
      "Train on 11000 samples, validate on 5335 samples\n",
      "Epoch 1/20\n",
      " - 4s - loss: 2.2065 - acc: 0.2065 - val_loss: 1.8101 - val_acc: 0.3201\n",
      "Epoch 2/20\n",
      " - 2s - loss: 1.7175 - acc: 0.3127 - val_loss: 1.5022 - val_acc: 0.4217\n",
      "Epoch 3/20\n",
      " - 2s - loss: 1.5191 - acc: 0.3802 - val_loss: 1.3550 - val_acc: 0.4789\n",
      "Epoch 4/20\n",
      " - 2s - loss: 1.4179 - acc: 0.4110 - val_loss: 1.2667 - val_acc: 0.5233\n",
      "Epoch 5/20\n",
      " - 2s - loss: 1.3384 - acc: 0.4566 - val_loss: 1.1903 - val_acc: 0.5526\n",
      "Epoch 6/20\n",
      " - 2s - loss: 1.2703 - acc: 0.4911 - val_loss: 1.1263 - val_acc: 0.5687\n",
      "Epoch 7/20\n",
      " - 2s - loss: 1.1941 - acc: 0.5294 - val_loss: 1.0585 - val_acc: 0.6202\n",
      "Epoch 8/20\n",
      " - 2s - loss: 1.1379 - acc: 0.5643 - val_loss: 0.9917 - val_acc: 0.6613\n",
      "Epoch 9/20\n",
      " - 2s - loss: 1.0830 - acc: 0.5887 - val_loss: 0.9447 - val_acc: 0.6733\n",
      "Epoch 10/20\n",
      " - 2s - loss: 1.0228 - acc: 0.6227 - val_loss: 0.8970 - val_acc: 0.6905\n",
      "Epoch 11/20\n",
      " - 2s - loss: 0.9799 - acc: 0.6388 - val_loss: 0.8662 - val_acc: 0.7057\n",
      "Epoch 12/20\n",
      " - 2s - loss: 0.9321 - acc: 0.6658 - val_loss: 0.8298 - val_acc: 0.7276\n",
      "Epoch 13/20\n",
      " - 2s - loss: 0.8979 - acc: 0.6759 - val_loss: 0.8052 - val_acc: 0.7374\n",
      "Epoch 14/20\n",
      " - 2s - loss: 0.8578 - acc: 0.6893 - val_loss: 0.7800 - val_acc: 0.7428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      " - 2s - loss: 0.8237 - acc: 0.7045 - val_loss: 0.7628 - val_acc: 0.7573\n",
      "Epoch 16/20\n",
      " - 2s - loss: 0.7911 - acc: 0.7156 - val_loss: 0.7393 - val_acc: 0.7653\n",
      "Epoch 17/20\n",
      " - 2s - loss: 0.7752 - acc: 0.7272 - val_loss: 0.7241 - val_acc: 0.7736\n",
      "Epoch 18/20\n",
      " - 2s - loss: 0.7334 - acc: 0.7441 - val_loss: 0.7141 - val_acc: 0.7728\n",
      "Epoch 19/20\n",
      " - 2s - loss: 0.7039 - acc: 0.7482 - val_loss: 0.7000 - val_acc: 0.7784\n",
      "Epoch 20/20\n",
      " - 2s - loss: 0.6712 - acc: 0.7608 - val_loss: 0.7036 - val_acc: 0.7769\n",
      "Test accuracy: 0.7769447047909287\n",
      "Train on 11000 samples, validate on 5335 samples\n",
      "Epoch 1/20\n",
      " - 4s - loss: 2.5054 - acc: 0.0934 - val_loss: 2.3318 - val_acc: 0.1738\n",
      "Epoch 2/20\n",
      " - 3s - loss: 2.4191 - acc: 0.1213 - val_loss: 2.2508 - val_acc: 0.2506\n",
      "Epoch 3/20\n",
      " - 2s - loss: 2.3460 - acc: 0.1577 - val_loss: 2.1762 - val_acc: 0.3233\n",
      "Epoch 4/20\n",
      " - 3s - loss: 2.2836 - acc: 0.1834 - val_loss: 2.1062 - val_acc: 0.3700\n",
      "Epoch 5/20\n",
      " - 2s - loss: 2.2222 - acc: 0.2104 - val_loss: 2.0380 - val_acc: 0.4036\n",
      "Epoch 6/20\n",
      " - 3s - loss: 2.1665 - acc: 0.2385 - val_loss: 1.9714 - val_acc: 0.4386\n",
      "Epoch 7/20\n",
      " - 3s - loss: 2.1066 - acc: 0.2653 - val_loss: 1.9056 - val_acc: 0.4679\n",
      "Epoch 8/20\n",
      " - 2s - loss: 2.0443 - acc: 0.2862 - val_loss: 1.8415 - val_acc: 0.4888\n",
      "Epoch 9/20\n",
      " - 2s - loss: 2.0038 - acc: 0.3069 - val_loss: 1.7789 - val_acc: 0.5089\n",
      "Epoch 10/20\n",
      " - 3s - loss: 1.9421 - acc: 0.3267 - val_loss: 1.7190 - val_acc: 0.5231\n",
      "Epoch 11/20\n",
      " - 3s - loss: 1.9031 - acc: 0.3355 - val_loss: 1.6644 - val_acc: 0.5366\n",
      "Epoch 12/20\n",
      " - 2s - loss: 1.8442 - acc: 0.3569 - val_loss: 1.6119 - val_acc: 0.5428\n",
      "Epoch 13/20\n",
      " - 2s - loss: 1.8008 - acc: 0.3708 - val_loss: 1.5634 - val_acc: 0.5524\n",
      "Epoch 14/20\n",
      " - 2s - loss: 1.7624 - acc: 0.3849 - val_loss: 1.5183 - val_acc: 0.5689\n",
      "Epoch 15/20\n",
      " - 2s - loss: 1.7215 - acc: 0.3977 - val_loss: 1.4767 - val_acc: 0.5762\n",
      "Epoch 16/20\n",
      " - 2s - loss: 1.6919 - acc: 0.4057 - val_loss: 1.4411 - val_acc: 0.5777\n",
      "Epoch 17/20\n",
      " - 2s - loss: 1.6623 - acc: 0.4168 - val_loss: 1.4065 - val_acc: 0.5861\n",
      "Epoch 18/20\n",
      " - 2s - loss: 1.6273 - acc: 0.4205 - val_loss: 1.3776 - val_acc: 0.5912\n",
      "Epoch 19/20\n",
      " - 2s - loss: 1.6134 - acc: 0.4241 - val_loss: 1.3498 - val_acc: 0.5948\n",
      "Epoch 20/20\n",
      " - 2s - loss: 1.5812 - acc: 0.4355 - val_loss: 1.3240 - val_acc: 0.6028\n",
      "Test accuracy: 0.6028116212565986\n",
      "Train on 11000 samples, validate on 5335 samples\n",
      "Epoch 1/20\n",
      " - 4s - loss: 2.1623 - acc: 0.2180 - val_loss: 1.4878 - val_acc: 0.5453\n",
      "Epoch 2/20\n",
      " - 3s - loss: 1.5749 - acc: 0.4111 - val_loss: 1.1239 - val_acc: 0.6514\n",
      "Epoch 3/20\n",
      " - 3s - loss: 1.2915 - acc: 0.5262 - val_loss: 0.9272 - val_acc: 0.7035\n",
      "Epoch 4/20\n",
      " - 3s - loss: 1.1166 - acc: 0.6007 - val_loss: 0.8292 - val_acc: 0.7408\n",
      "Epoch 5/20\n",
      " - 3s - loss: 0.9772 - acc: 0.6545 - val_loss: 0.7528 - val_acc: 0.7590\n",
      "Epoch 6/20\n",
      " - 3s - loss: 0.8441 - acc: 0.7088 - val_loss: 0.6944 - val_acc: 0.7738\n",
      "Epoch 7/20\n",
      " - 3s - loss: 0.7507 - acc: 0.7454 - val_loss: 0.6649 - val_acc: 0.7889\n",
      "Epoch 8/20\n",
      " - 3s - loss: 0.6437 - acc: 0.7766 - val_loss: 0.6173 - val_acc: 0.8022\n",
      "Epoch 9/20\n",
      " - 3s - loss: 0.5640 - acc: 0.8075 - val_loss: 0.6151 - val_acc: 0.8082\n",
      "Epoch 10/20\n",
      " - 3s - loss: 0.4990 - acc: 0.8314 - val_loss: 0.6179 - val_acc: 0.8092\n",
      "Epoch 11/20\n",
      " - 3s - loss: 0.4286 - acc: 0.8530 - val_loss: 0.6155 - val_acc: 0.8172\n",
      "Epoch 12/20\n",
      " - 3s - loss: 0.3839 - acc: 0.8705 - val_loss: 0.6163 - val_acc: 0.8186\n",
      "Epoch 13/20\n",
      " - 3s - loss: 0.3513 - acc: 0.8822 - val_loss: 0.6173 - val_acc: 0.8212\n",
      "Epoch 14/20\n",
      " - 3s - loss: 0.2997 - acc: 0.9044 - val_loss: 0.6360 - val_acc: 0.8180\n",
      "Epoch 15/20\n",
      " - 3s - loss: 0.2727 - acc: 0.9087 - val_loss: 0.6383 - val_acc: 0.8184\n",
      "Epoch 16/20\n",
      " - 3s - loss: 0.2458 - acc: 0.9188 - val_loss: 0.6548 - val_acc: 0.8193\n",
      "Epoch 17/20\n",
      " - 3s - loss: 0.2220 - acc: 0.9280 - val_loss: 0.6835 - val_acc: 0.8214\n",
      "Epoch 18/20\n",
      " - 3s - loss: 0.2070 - acc: 0.9327 - val_loss: 0.6686 - val_acc: 0.8195\n",
      "Epoch 19/20\n",
      " - 3s - loss: 0.1904 - acc: 0.9390 - val_loss: 0.7135 - val_acc: 0.8210\n",
      "Epoch 20/20\n",
      " - 3s - loss: 0.1698 - acc: 0.9439 - val_loss: 0.7081 - val_acc: 0.8238\n",
      "Test accuracy: 0.8238050609296353\n",
      "Train on 11000 samples, validate on 5335 samples\n",
      "Epoch 1/20\n",
      " - 4s - loss: 2.1196 - acc: 0.2354 - val_loss: 1.4512 - val_acc: 0.5582\n",
      "Epoch 2/20\n",
      " - 3s - loss: 1.5718 - acc: 0.4249 - val_loss: 1.0678 - val_acc: 0.6658\n",
      "Epoch 3/20\n",
      " - 3s - loss: 1.2956 - acc: 0.5433 - val_loss: 0.9023 - val_acc: 0.7164\n",
      "Epoch 4/20\n",
      " - 3s - loss: 1.0921 - acc: 0.6162 - val_loss: 0.8040 - val_acc: 0.7419\n",
      "Epoch 5/20\n",
      " - 3s - loss: 0.9263 - acc: 0.6799 - val_loss: 0.7332 - val_acc: 0.7597\n",
      "Epoch 6/20\n",
      " - 3s - loss: 0.7948 - acc: 0.7273 - val_loss: 0.6669 - val_acc: 0.7861\n",
      "Epoch 7/20\n",
      " - 3s - loss: 0.6636 - acc: 0.7786 - val_loss: 0.6187 - val_acc: 0.8037\n",
      "Epoch 8/20\n",
      " - 3s - loss: 0.5472 - acc: 0.8198 - val_loss: 0.6215 - val_acc: 0.8075\n",
      "Epoch 9/20\n",
      " - 3s - loss: 0.4493 - acc: 0.8528 - val_loss: 0.5988 - val_acc: 0.8195\n",
      "Epoch 10/20\n",
      " - 3s - loss: 0.3739 - acc: 0.8786 - val_loss: 0.6202 - val_acc: 0.8195\n",
      "Epoch 11/20\n",
      " - 3s - loss: 0.2991 - acc: 0.9059 - val_loss: 0.6143 - val_acc: 0.8206\n",
      "Epoch 12/20\n",
      " - 3s - loss: 0.2553 - acc: 0.9211 - val_loss: 0.6624 - val_acc: 0.8186\n",
      "Epoch 13/20\n",
      " - 3s - loss: 0.2199 - acc: 0.9328 - val_loss: 0.6787 - val_acc: 0.8167\n",
      "Epoch 14/20\n",
      " - 3s - loss: 0.1881 - acc: 0.9429 - val_loss: 0.6779 - val_acc: 0.8202\n",
      "Epoch 15/20\n",
      " - 3s - loss: 0.1657 - acc: 0.9530 - val_loss: 0.7366 - val_acc: 0.8120\n",
      "Epoch 16/20\n",
      " - 3s - loss: 0.1510 - acc: 0.9555 - val_loss: 0.7139 - val_acc: 0.8240\n",
      "Epoch 17/20\n",
      " - 3s - loss: 0.1368 - acc: 0.9599 - val_loss: 0.7492 - val_acc: 0.8229\n",
      "Epoch 18/20\n",
      " - 3s - loss: 0.1108 - acc: 0.9685 - val_loss: 0.7687 - val_acc: 0.8283\n",
      "Epoch 19/20\n",
      " - 3s - loss: 0.0983 - acc: 0.9725 - val_loss: 0.8176 - val_acc: 0.8206\n",
      "Epoch 20/20\n",
      " - 3s - loss: 0.0935 - acc: 0.9730 - val_loss: 0.8134 - val_acc: 0.8264\n",
      "Test accuracy: 0.8264292407840239\n",
      "Train on 11000 samples, validate on 5335 samples\n",
      "Epoch 1/20\n",
      " - 4s - loss: 2.1162 - acc: 0.2452 - val_loss: 1.4199 - val_acc: 0.5846\n",
      "Epoch 2/20\n",
      " - 3s - loss: 1.5493 - acc: 0.4416 - val_loss: 1.0512 - val_acc: 0.6622\n",
      "Epoch 3/20\n",
      " - 3s - loss: 1.2647 - acc: 0.5530 - val_loss: 0.8981 - val_acc: 0.7130\n",
      "Epoch 4/20\n",
      " - 3s - loss: 1.0781 - acc: 0.6267 - val_loss: 0.7968 - val_acc: 0.7462\n",
      "Epoch 5/20\n",
      " - 3s - loss: 0.9323 - acc: 0.6798 - val_loss: 0.7310 - val_acc: 0.7663\n",
      "Epoch 6/20\n",
      " - 3s - loss: 0.7740 - acc: 0.7397 - val_loss: 0.6687 - val_acc: 0.7835\n",
      "Epoch 7/20\n",
      " - 3s - loss: 0.6580 - acc: 0.7757 - val_loss: 0.6429 - val_acc: 0.7964\n",
      "Epoch 8/20\n",
      " - 3s - loss: 0.5509 - acc: 0.8178 - val_loss: 0.6365 - val_acc: 0.7951\n",
      "Epoch 9/20\n",
      " - 3s - loss: 0.4768 - acc: 0.8427 - val_loss: 0.6093 - val_acc: 0.8079\n",
      "Epoch 10/20\n",
      " - 3s - loss: 0.3845 - acc: 0.8736 - val_loss: 0.6218 - val_acc: 0.8129\n",
      "Epoch 11/20\n",
      " - 3s - loss: 0.3226 - acc: 0.8946 - val_loss: 0.6369 - val_acc: 0.8131\n",
      "Epoch 12/20\n",
      " - 3s - loss: 0.2649 - acc: 0.9159 - val_loss: 0.6530 - val_acc: 0.8144\n",
      "Epoch 13/20\n",
      " - 3s - loss: 0.2331 - acc: 0.9242 - val_loss: 0.6627 - val_acc: 0.8152\n",
      "Epoch 14/20\n",
      " - 3s - loss: 0.1964 - acc: 0.9403 - val_loss: 0.7050 - val_acc: 0.8150\n",
      "Epoch 15/20\n",
      " - 3s - loss: 0.1627 - acc: 0.9522 - val_loss: 0.7396 - val_acc: 0.8202\n",
      "Epoch 16/20\n",
      " - 3s - loss: 0.1353 - acc: 0.9577 - val_loss: 0.7803 - val_acc: 0.8195\n",
      "Epoch 17/20\n",
      " - 3s - loss: 0.1282 - acc: 0.9625 - val_loss: 0.7649 - val_acc: 0.8191\n",
      "Epoch 18/20\n",
      " - 3s - loss: 0.1131 - acc: 0.9675 - val_loss: 0.7871 - val_acc: 0.8242\n",
      "Epoch 19/20\n",
      " - 3s - loss: 0.0932 - acc: 0.9716 - val_loss: 0.8357 - val_acc: 0.8171\n",
      "Epoch 20/20\n",
      " - 3s - loss: 0.0911 - acc: 0.9742 - val_loss: 0.8216 - val_acc: 0.8217\n",
      "Test accuracy: 0.8217432052595323\n",
      "Train on 11000 samples, validate on 5335 samples\n",
      "Epoch 1/20\n",
      " - 5s - loss: 2.4239 - acc: 0.1326 - val_loss: 2.1410 - val_acc: 0.3803\n",
      "Epoch 2/20\n",
      " - 3s - loss: 2.1703 - acc: 0.2095 - val_loss: 1.7951 - val_acc: 0.4345\n",
      "Epoch 3/20\n",
      " - 3s - loss: 1.9807 - acc: 0.2708 - val_loss: 1.5790 - val_acc: 0.5192\n",
      "Epoch 4/20\n",
      " - 3s - loss: 1.7978 - acc: 0.3312 - val_loss: 1.3987 - val_acc: 0.5548\n",
      "Epoch 5/20\n",
      " - 3s - loss: 1.6402 - acc: 0.3773 - val_loss: 1.2701 - val_acc: 0.6135\n",
      "Epoch 6/20\n",
      " - 3s - loss: 1.4918 - acc: 0.4312 - val_loss: 1.1700 - val_acc: 0.6439\n",
      "Epoch 7/20\n",
      " - 3s - loss: 1.3832 - acc: 0.4657 - val_loss: 1.0931 - val_acc: 0.6868\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 3s - loss: 1.2772 - acc: 0.5048 - val_loss: 1.0324 - val_acc: 0.6939\n",
      "Epoch 9/20\n",
      " - 3s - loss: 1.1865 - acc: 0.5381 - val_loss: 0.9762 - val_acc: 0.7183\n",
      "Epoch 10/20\n",
      " - 3s - loss: 1.1246 - acc: 0.5668 - val_loss: 0.9377 - val_acc: 0.7123\n",
      "Epoch 11/20\n",
      " - 3s - loss: 1.0464 - acc: 0.5966 - val_loss: 0.8836 - val_acc: 0.7366\n",
      "Epoch 12/20\n",
      " - 3s - loss: 0.9776 - acc: 0.6186 - val_loss: 0.8470 - val_acc: 0.7344\n",
      "Epoch 13/20\n",
      " - 3s - loss: 0.8998 - acc: 0.6469 - val_loss: 0.8217 - val_acc: 0.7582\n",
      "Epoch 14/20\n",
      " - 3s - loss: 0.8489 - acc: 0.6768 - val_loss: 0.7930 - val_acc: 0.7618\n",
      "Epoch 15/20\n",
      " - 3s - loss: 0.7702 - acc: 0.6940 - val_loss: 0.7716 - val_acc: 0.7713\n",
      "Epoch 16/20\n",
      " - 3s - loss: 0.7395 - acc: 0.7104 - val_loss: 0.7678 - val_acc: 0.7709\n",
      "Epoch 17/20\n",
      " - 3s - loss: 0.6834 - acc: 0.7372 - val_loss: 0.7526 - val_acc: 0.7820\n",
      "Epoch 18/20\n",
      " - 3s - loss: 0.6309 - acc: 0.7499 - val_loss: 0.7635 - val_acc: 0.7756\n",
      "Epoch 19/20\n",
      " - 3s - loss: 0.6039 - acc: 0.7655 - val_loss: 0.7523 - val_acc: 0.7784\n",
      "Epoch 20/20\n",
      " - 3s - loss: 0.5812 - acc: 0.7754 - val_loss: 0.7188 - val_acc: 0.7974\n",
      "Test accuracy: 0.7973758201120943\n",
      "Train on 11000 samples, validate on 5335 samples\n",
      "Epoch 1/20\n",
      " - 3s - loss: 1.9444 - acc: 0.2886 - val_loss: 1.2250 - val_acc: 0.6146\n",
      "Epoch 2/20\n",
      " - 2s - loss: 1.3750 - acc: 0.5083 - val_loss: 0.9373 - val_acc: 0.6990\n",
      "Epoch 3/20\n",
      " - 2s - loss: 1.1414 - acc: 0.6011 - val_loss: 0.8132 - val_acc: 0.7344\n",
      "Epoch 4/20\n",
      " - 2s - loss: 0.9510 - acc: 0.6786 - val_loss: 0.7433 - val_acc: 0.7599\n",
      "Epoch 5/20\n",
      " - 2s - loss: 0.8031 - acc: 0.7330 - val_loss: 0.6945 - val_acc: 0.7717\n",
      "Epoch 6/20\n",
      " - 2s - loss: 0.6699 - acc: 0.7795 - val_loss: 0.6519 - val_acc: 0.7846\n",
      "Epoch 7/20\n",
      " - 2s - loss: 0.5487 - acc: 0.8200 - val_loss: 0.6332 - val_acc: 0.7953\n",
      "Epoch 8/20\n",
      " - 2s - loss: 0.4641 - acc: 0.8498 - val_loss: 0.6259 - val_acc: 0.8013\n",
      "Epoch 9/20\n",
      " - 2s - loss: 0.3600 - acc: 0.8866 - val_loss: 0.6428 - val_acc: 0.8019\n",
      "Epoch 10/20\n",
      " - 2s - loss: 0.2862 - acc: 0.9089 - val_loss: 0.6858 - val_acc: 0.8000\n",
      "Epoch 11/20\n",
      " - 2s - loss: 0.2305 - acc: 0.9260 - val_loss: 0.6863 - val_acc: 0.8105\n",
      "Epoch 12/20\n",
      " - 2s - loss: 0.1949 - acc: 0.9405 - val_loss: 0.7313 - val_acc: 0.8097\n",
      "Epoch 13/20\n",
      " - 2s - loss: 0.1593 - acc: 0.9505 - val_loss: 0.7195 - val_acc: 0.8184\n",
      "Epoch 14/20\n",
      " - 2s - loss: 0.1425 - acc: 0.9586 - val_loss: 0.8105 - val_acc: 0.8062\n",
      "Epoch 15/20\n",
      " - 2s - loss: 0.1277 - acc: 0.9631 - val_loss: 0.7923 - val_acc: 0.8139\n",
      "Epoch 16/20\n",
      " - 2s - loss: 0.1012 - acc: 0.9706 - val_loss: 0.7937 - val_acc: 0.8174\n",
      "Epoch 17/20\n",
      " - 2s - loss: 0.0872 - acc: 0.9735 - val_loss: 0.8430 - val_acc: 0.8144\n",
      "Epoch 18/20\n",
      " - 2s - loss: 0.0831 - acc: 0.9755 - val_loss: 0.8948 - val_acc: 0.8135\n",
      "Epoch 19/20\n",
      " - 2s - loss: 0.0862 - acc: 0.9737 - val_loss: 0.8799 - val_acc: 0.8148\n",
      "Epoch 20/20\n",
      " - 2s - loss: 0.0821 - acc: 0.9769 - val_loss: 0.9010 - val_acc: 0.8172\n",
      "Test accuracy: 0.817244611114906\n",
      "Train on 11000 samples, validate on 5335 samples\n",
      "Epoch 1/20\n",
      " - 5s - loss: 2.1252 - acc: 0.2291 - val_loss: 1.4719 - val_acc: 0.5342\n",
      "Epoch 2/20\n",
      " - 4s - loss: 1.5875 - acc: 0.4180 - val_loss: 1.0964 - val_acc: 0.6592\n",
      "Epoch 3/20\n",
      " - 4s - loss: 1.2872 - acc: 0.5406 - val_loss: 0.9114 - val_acc: 0.7068\n",
      "Epoch 4/20\n",
      " - 4s - loss: 1.0783 - acc: 0.6281 - val_loss: 0.7885 - val_acc: 0.7498\n",
      "Epoch 5/20\n",
      " - 4s - loss: 0.9366 - acc: 0.6784 - val_loss: 0.7325 - val_acc: 0.7649\n",
      "Epoch 6/20\n",
      " - 4s - loss: 0.7876 - acc: 0.7284 - val_loss: 0.6641 - val_acc: 0.7916\n",
      "Epoch 7/20\n",
      " - 4s - loss: 0.6720 - acc: 0.7749 - val_loss: 0.6553 - val_acc: 0.7912\n",
      "Epoch 8/20\n",
      " - 4s - loss: 0.5617 - acc: 0.8124 - val_loss: 0.6205 - val_acc: 0.8071\n",
      "Epoch 9/20\n",
      " - 4s - loss: 0.4675 - acc: 0.8422 - val_loss: 0.6417 - val_acc: 0.8002\n",
      "Epoch 10/20\n",
      " - 4s - loss: 0.3921 - acc: 0.8730 - val_loss: 0.6146 - val_acc: 0.8141\n",
      "Epoch 11/20\n",
      " - 4s - loss: 0.3315 - acc: 0.8956 - val_loss: 0.6448 - val_acc: 0.8156\n",
      "Epoch 12/20\n",
      " - 4s - loss: 0.2923 - acc: 0.9081 - val_loss: 0.6785 - val_acc: 0.8133\n",
      "Epoch 13/20\n",
      " - 4s - loss: 0.2584 - acc: 0.9180 - val_loss: 0.6955 - val_acc: 0.8109\n",
      "Epoch 14/20\n",
      " - 4s - loss: 0.2050 - acc: 0.9357 - val_loss: 0.6978 - val_acc: 0.8157\n",
      "Epoch 15/20\n",
      " - 4s - loss: 0.1837 - acc: 0.9410 - val_loss: 0.7582 - val_acc: 0.8184\n",
      "Epoch 16/20\n",
      " - 4s - loss: 0.1714 - acc: 0.9487 - val_loss: 0.7673 - val_acc: 0.8133\n",
      "Epoch 17/20\n",
      " - 4s - loss: 0.1575 - acc: 0.9529 - val_loss: 0.7771 - val_acc: 0.8150\n",
      "Epoch 18/20\n",
      " - 4s - loss: 0.1265 - acc: 0.9624 - val_loss: 0.8236 - val_acc: 0.8197\n",
      "Epoch 19/20\n",
      " - 3s - loss: 0.1227 - acc: 0.9617 - val_loss: 0.8128 - val_acc: 0.8223\n",
      "Epoch 20/20\n",
      " - 4s - loss: 0.1134 - acc: 0.9671 - val_loss: 0.8396 - val_acc: 0.8225\n",
      "Test accuracy: 0.8224929709130621\n",
      "Train on 11000 samples, validate on 5335 samples\n",
      "Epoch 1/20\n",
      " - 5s - loss: 1.9287 - acc: 0.3076 - val_loss: 1.2479 - val_acc: 0.5940\n",
      "Epoch 2/20\n",
      " - 3s - loss: 1.3764 - acc: 0.4962 - val_loss: 0.9811 - val_acc: 0.6857\n",
      "Epoch 3/20\n",
      " - 3s - loss: 1.1759 - acc: 0.5851 - val_loss: 0.8570 - val_acc: 0.7376\n",
      "Epoch 4/20\n",
      " - 3s - loss: 0.9970 - acc: 0.6497 - val_loss: 0.7726 - val_acc: 0.7488\n",
      "Epoch 5/20\n",
      " - 3s - loss: 0.8882 - acc: 0.6898 - val_loss: 0.7192 - val_acc: 0.7698\n",
      "Epoch 6/20\n",
      " - 3s - loss: 0.7872 - acc: 0.7309 - val_loss: 0.6555 - val_acc: 0.7871\n",
      "Epoch 7/20\n",
      " - 3s - loss: 0.6908 - acc: 0.7626 - val_loss: 0.6305 - val_acc: 0.7904\n",
      "Epoch 8/20\n",
      " - 3s - loss: 0.5931 - acc: 0.7899 - val_loss: 0.6072 - val_acc: 0.8011\n",
      "Epoch 9/20\n",
      " - 3s - loss: 0.5109 - acc: 0.8218 - val_loss: 0.6016 - val_acc: 0.8082\n",
      "Epoch 10/20\n",
      " - 3s - loss: 0.4434 - acc: 0.8459 - val_loss: 0.5908 - val_acc: 0.8195\n",
      "Epoch 11/20\n",
      " - 3s - loss: 0.3863 - acc: 0.8659 - val_loss: 0.6210 - val_acc: 0.8111\n",
      "Epoch 12/20\n",
      " - 3s - loss: 0.3321 - acc: 0.8878 - val_loss: 0.6191 - val_acc: 0.8210\n",
      "Epoch 13/20\n",
      " - 3s - loss: 0.3055 - acc: 0.8963 - val_loss: 0.6140 - val_acc: 0.8238\n",
      "Epoch 14/20\n",
      " - 3s - loss: 0.2634 - acc: 0.9089 - val_loss: 0.6427 - val_acc: 0.8199\n",
      "Epoch 15/20\n",
      " - 3s - loss: 0.2413 - acc: 0.9190 - val_loss: 0.6575 - val_acc: 0.8206\n",
      "Epoch 16/20\n",
      " - 3s - loss: 0.2162 - acc: 0.9285 - val_loss: 0.6767 - val_acc: 0.8240\n",
      "Epoch 17/20\n",
      " - 3s - loss: 0.1959 - acc: 0.9376 - val_loss: 0.6811 - val_acc: 0.8257\n",
      "Epoch 18/20\n",
      " - 3s - loss: 0.1764 - acc: 0.9436 - val_loss: 0.7107 - val_acc: 0.8272\n",
      "Epoch 19/20\n",
      " - 3s - loss: 0.1670 - acc: 0.9449 - val_loss: 0.7038 - val_acc: 0.8249\n",
      "Epoch 20/20\n",
      " - 3s - loss: 0.1544 - acc: 0.9482 - val_loss: 0.7249 - val_acc: 0.8262\n",
      "Test accuracy: 0.8262417994488481\n",
      "Train on 11000 samples, validate on 5335 samples\n",
      "Epoch 1/20\n",
      " - 5s - loss: 1.8382 - acc: 0.3306 - val_loss: 1.1333 - val_acc: 0.6242\n",
      "Epoch 2/20\n",
      " - 3s - loss: 1.2619 - acc: 0.5441 - val_loss: 0.8978 - val_acc: 0.6999\n",
      "Epoch 3/20\n",
      " - 3s - loss: 1.0405 - acc: 0.6370 - val_loss: 0.7849 - val_acc: 0.7438\n",
      "Epoch 4/20\n",
      " - 3s - loss: 0.8888 - acc: 0.6959 - val_loss: 0.7111 - val_acc: 0.7691\n",
      "Epoch 5/20\n",
      " - 3s - loss: 0.7311 - acc: 0.7490 - val_loss: 0.6540 - val_acc: 0.7921\n",
      "Epoch 6/20\n",
      " - 3s - loss: 0.6046 - acc: 0.7946 - val_loss: 0.6188 - val_acc: 0.8007\n",
      "Epoch 7/20\n",
      " - 3s - loss: 0.4973 - acc: 0.8341 - val_loss: 0.6102 - val_acc: 0.8139\n",
      "Epoch 8/20\n",
      " - 3s - loss: 0.4099 - acc: 0.8633 - val_loss: 0.5883 - val_acc: 0.8124\n",
      "Epoch 9/20\n",
      " - 3s - loss: 0.3209 - acc: 0.8947 - val_loss: 0.5872 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      " - 3s - loss: 0.2631 - acc: 0.9116 - val_loss: 0.6225 - val_acc: 0.8199\n",
      "Epoch 11/20\n",
      " - 3s - loss: 0.2070 - acc: 0.9322 - val_loss: 0.6542 - val_acc: 0.8189\n",
      "Epoch 12/20\n",
      " - 3s - loss: 0.1621 - acc: 0.9471 - val_loss: 0.6746 - val_acc: 0.8238\n",
      "Epoch 13/20\n",
      " - 3s - loss: 0.1464 - acc: 0.9511 - val_loss: 0.6751 - val_acc: 0.8223\n",
      "Epoch 14/20\n",
      " - 3s - loss: 0.1238 - acc: 0.9605 - val_loss: 0.7534 - val_acc: 0.8234\n",
      "Epoch 15/20\n",
      " - 3s - loss: 0.1123 - acc: 0.9645 - val_loss: 0.7420 - val_acc: 0.8232\n",
      "Epoch 16/20\n",
      " - 3s - loss: 0.0920 - acc: 0.9701 - val_loss: 0.7789 - val_acc: 0.8184\n",
      "Epoch 17/20\n",
      " - 3s - loss: 0.1037 - acc: 0.9686 - val_loss: 0.7956 - val_acc: 0.8197\n",
      "Epoch 18/20\n",
      " - 3s - loss: 0.0872 - acc: 0.9742 - val_loss: 0.8260 - val_acc: 0.8146\n",
      "Epoch 19/20\n",
      " - 3s - loss: 0.0780 - acc: 0.9742 - val_loss: 0.8150 - val_acc: 0.8212\n",
      "Epoch 20/20\n",
      " - 3s - loss: 0.0715 - acc: 0.9774 - val_loss: 0.8497 - val_acc: 0.8216\n",
      "Test accuracy: 0.8215557637902879\n",
      "Train on 11000 samples, validate on 5335 samples\n",
      "Epoch 1/20\n",
      " - 3s - loss: 2.9342 - acc: 0.0935 - val_loss: 2.3966 - val_acc: 0.1053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      " - 2s - loss: 2.4367 - acc: 0.0935 - val_loss: 2.3959 - val_acc: 0.1125\n",
      "Epoch 3/20\n",
      " - 2s - loss: 2.4163 - acc: 0.0950 - val_loss: 2.3949 - val_acc: 0.0977\n",
      "Epoch 4/20\n",
      " - 2s - loss: 2.4013 - acc: 0.0992 - val_loss: 2.3867 - val_acc: 0.1385\n",
      "Epoch 5/20\n",
      " - 2s - loss: 2.3935 - acc: 0.1056 - val_loss: 2.3758 - val_acc: 0.1584\n",
      "Epoch 6/20\n",
      " - 2s - loss: 2.3786 - acc: 0.1145 - val_loss: 2.3573 - val_acc: 0.1974\n",
      "Epoch 7/20\n",
      " - 2s - loss: 2.3457 - acc: 0.1267 - val_loss: 2.3280 - val_acc: 0.2386\n",
      "Epoch 8/20\n",
      " - 2s - loss: 2.3180 - acc: 0.1441 - val_loss: 2.2899 - val_acc: 0.2821\n",
      "Epoch 9/20\n",
      " - 2s - loss: 2.2811 - acc: 0.1538 - val_loss: 2.2447 - val_acc: 0.2855\n",
      "Epoch 10/20\n",
      " - 2s - loss: 2.2433 - acc: 0.1615 - val_loss: 2.1752 - val_acc: 0.2939\n",
      "Epoch 11/20\n",
      " - 2s - loss: 2.2060 - acc: 0.1773 - val_loss: 2.1396 - val_acc: 0.2956\n",
      "Epoch 12/20\n",
      " - 2s - loss: 2.1687 - acc: 0.1885 - val_loss: 2.0636 - val_acc: 0.3113\n",
      "Epoch 13/20\n",
      " - 2s - loss: 2.1409 - acc: 0.1989 - val_loss: 2.0164 - val_acc: 0.3185\n",
      "Epoch 14/20\n",
      " - 2s - loss: 2.0814 - acc: 0.2181 - val_loss: 1.9586 - val_acc: 0.3181\n",
      "Epoch 15/20\n",
      " - 2s - loss: 2.0552 - acc: 0.2192 - val_loss: 1.8963 - val_acc: 0.3263\n",
      "Epoch 16/20\n",
      " - 2s - loss: 2.0345 - acc: 0.2245 - val_loss: 1.9047 - val_acc: 0.3110\n",
      "Epoch 17/20\n",
      " - 2s - loss: 2.0001 - acc: 0.2368 - val_loss: 1.8403 - val_acc: 0.2975\n",
      "Epoch 18/20\n",
      " - 2s - loss: 1.9726 - acc: 0.2432 - val_loss: 1.8035 - val_acc: 0.2806\n",
      "Epoch 19/20\n",
      " - 2s - loss: 1.9629 - acc: 0.2435 - val_loss: 1.8124 - val_acc: 0.2817\n",
      "Epoch 20/20\n",
      " - 2s - loss: 1.9273 - acc: 0.2473 - val_loss: 1.7879 - val_acc: 0.2667\n",
      "Test accuracy: 0.26672914714500967\n",
      "Train on 11000 samples, validate on 5335 samples\n",
      "Epoch 1/20\n",
      " - 3s - loss: 2.3737 - acc: 0.1392 - val_loss: 2.0907 - val_acc: 0.3398\n",
      "Epoch 2/20\n",
      " - 1s - loss: 1.9895 - acc: 0.2678 - val_loss: 1.5295 - val_acc: 0.4720\n",
      "Epoch 3/20\n",
      " - 1s - loss: 1.6545 - acc: 0.3787 - val_loss: 1.2507 - val_acc: 0.5882\n",
      "Epoch 4/20\n",
      " - 1s - loss: 1.4615 - acc: 0.4505 - val_loss: 1.1031 - val_acc: 0.6240\n",
      "Epoch 5/20\n",
      " - 1s - loss: 1.3134 - acc: 0.5167 - val_loss: 1.0192 - val_acc: 0.6549\n",
      "Epoch 6/20\n",
      " - 1s - loss: 1.2044 - acc: 0.5624 - val_loss: 0.9602 - val_acc: 0.6679\n",
      "Epoch 7/20\n",
      " - 1s - loss: 1.1150 - acc: 0.5947 - val_loss: 0.9104 - val_acc: 0.6988\n",
      "Epoch 8/20\n",
      " - 1s - loss: 1.0281 - acc: 0.6203 - val_loss: 0.8659 - val_acc: 0.7104\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.9649 - acc: 0.6539 - val_loss: 0.8517 - val_acc: 0.7123\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.8816 - acc: 0.6815 - val_loss: 0.8360 - val_acc: 0.7286\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.8333 - acc: 0.6947 - val_loss: 0.8116 - val_acc: 0.7387\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.7680 - acc: 0.7215 - val_loss: 0.8196 - val_acc: 0.7425\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.7203 - acc: 0.7398 - val_loss: 0.7919 - val_acc: 0.7513\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.6846 - acc: 0.7575 - val_loss: 0.7930 - val_acc: 0.7513\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.6232 - acc: 0.7800 - val_loss: 0.8024 - val_acc: 0.7561\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.5776 - acc: 0.7925 - val_loss: 0.7826 - val_acc: 0.7597\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.5570 - acc: 0.8101 - val_loss: 0.8004 - val_acc: 0.7653\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.5146 - acc: 0.8214 - val_loss: 0.7971 - val_acc: 0.7685\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.4746 - acc: 0.8337 - val_loss: 0.8076 - val_acc: 0.7648\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.4534 - acc: 0.8430 - val_loss: 0.8219 - val_acc: 0.7683\n",
      "Test accuracy: 0.7683223992614067\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train, X_val, Y_val,X_test,Y_test = data()\n",
    "\n",
    "best_run, best_model = optim.minimize(model=model,\n",
    "                                      data=data,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=30,\n",
    "                                      trials=Trials(),\n",
    "                                      notebook_name='DNNoptimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Activation': 0, 'Activation_1': 0, 'Activation_2': 0, 'Dense': 3, 'Dense_1': 1, 'Dense_2': 0, 'Dropout': 0.2537673020472459, 'Dropout_1': 0.5899272287473123, 'Dropout_2': 0.6639991450877202, 'batch_size': 1, 'choiceval': 0, 'conditional': 1, 'lr': 0, 'lr_1': 1, 'lr_2': 2}\n"
     ]
    }
   ],
   "source": [
    "# print the best model with optimized parameters\n",
    "print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model based on optimization\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(1024, activation='relu', input_shape=(34*34,)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.59))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.66))\n",
    "model.add(layers.Dense(11, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'Activation': 0, 'Activation_1': 0, 'Activation_2': 0, 'Dense': 3, 'Dense_1': 1, 'Dense_2': 0, 'Dropout': 0.2537673020472459, 'Dropout_1': 0.5899272287473123, 'Dropout_2': 0.6639991450877202, 'batch_size': 1, 'choiceval': 0, 'conditional': 1, 'lr': 0, 'lr_1': 1, 'lr_2': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11000 samples, validate on 5335 samples\n",
      "Epoch 1/20\n",
      "11000/11000 [==============================] - 8s 696us/step - loss: 2.0547 - acc: 0.2572 - val_loss: 1.3395 - val_acc: 0.5432\n",
      "Epoch 2/20\n",
      "11000/11000 [==============================] - 5s 489us/step - loss: 1.4720 - acc: 0.4630 - val_loss: 1.0060 - val_acc: 0.6860\n",
      "Epoch 3/20\n",
      "11000/11000 [==============================] - 5s 487us/step - loss: 1.2019 - acc: 0.5706 - val_loss: 0.8658 - val_acc: 0.7095\n",
      "Epoch 4/20\n",
      "11000/11000 [==============================] - 6s 510us/step - loss: 0.9784 - acc: 0.6600 - val_loss: 0.7498 - val_acc: 0.7558\n",
      "Epoch 5/20\n",
      "11000/11000 [==============================] - 5s 494us/step - loss: 0.8276 - acc: 0.7197 - val_loss: 0.6780 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "11000/11000 [==============================] - 5s 488us/step - loss: 0.6811 - acc: 0.7718 - val_loss: 0.6375 - val_acc: 0.7918\n",
      "Epoch 7/20\n",
      "11000/11000 [==============================] - 5s 481us/step - loss: 0.5325 - acc: 0.8244 - val_loss: 0.6117 - val_acc: 0.8127\n",
      "Epoch 8/20\n",
      "11000/11000 [==============================] - 6s 512us/step - loss: 0.4470 - acc: 0.8560 - val_loss: 0.6243 - val_acc: 0.8135\n",
      "Epoch 9/20\n",
      "11000/11000 [==============================] - 5s 494us/step - loss: 0.3706 - acc: 0.8812 - val_loss: 0.6263 - val_acc: 0.8171\n",
      "Epoch 10/20\n",
      "11000/11000 [==============================] - 6s 501us/step - loss: 0.2977 - acc: 0.9053 - val_loss: 0.6359 - val_acc: 0.8251\n",
      "Epoch 11/20\n",
      "11000/11000 [==============================] - 5s 487us/step - loss: 0.2512 - acc: 0.9201 - val_loss: 0.6636 - val_acc: 0.8195\n",
      "Epoch 12/20\n",
      "11000/11000 [==============================] - 5s 466us/step - loss: 0.2073 - acc: 0.9362 - val_loss: 0.6642 - val_acc: 0.8214\n",
      "Epoch 13/20\n",
      "11000/11000 [==============================] - 6s 559us/step - loss: 0.1944 - acc: 0.9438 - val_loss: 0.7116 - val_acc: 0.8206\n",
      "Epoch 14/20\n",
      "11000/11000 [==============================] - 6s 500us/step - loss: 0.1669 - acc: 0.9469 - val_loss: 0.7439 - val_acc: 0.8178\n",
      "Epoch 15/20\n",
      "11000/11000 [==============================] - 6s 515us/step - loss: 0.1308 - acc: 0.9603 - val_loss: 0.7931 - val_acc: 0.8167\n",
      "Epoch 16/20\n",
      "11000/11000 [==============================] - 6s 502us/step - loss: 0.1419 - acc: 0.9568 - val_loss: 0.7815 - val_acc: 0.8197\n",
      "Epoch 17/20\n",
      "11000/11000 [==============================] - 5s 492us/step - loss: 0.1320 - acc: 0.9631 - val_loss: 0.7626 - val_acc: 0.8232\n",
      "Epoch 18/20\n",
      "11000/11000 [==============================] - 5s 488us/step - loss: 0.1069 - acc: 0.9682 - val_loss: 0.8191 - val_acc: 0.8193\n",
      "Epoch 19/20\n",
      "11000/11000 [==============================] - 6s 505us/step - loss: 0.1060 - acc: 0.9712 - val_loss: 0.8584 - val_acc: 0.8144\n",
      "Epoch 20/20\n",
      "11000/11000 [==============================] - 5s 492us/step - loss: 0.0932 - acc: 0.9745 - val_loss: 0.8330 - val_acc: 0.8249\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    Y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=128,\n",
    "                    validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the graph\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 10\n"
     ]
    }
   ],
   "source": [
    "print(np.argmin(val_loss)+1, np.argmax(val_acc)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 164ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8474226593971252"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the model on testing set\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, Y_test,steps=7)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
